{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "# set some styling defaults for matplotlib\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "mpl.rcParams[\"figure.dpi\"] = 90  # change this to set apparent figure size\n",
    "mpl.rcParams[\"figure.figsize\"] = (7, 3)\n",
    "mpl.rcParams[\"figure.frameon\"] = False\n",
    "\n",
    "# set decimal precision to 3 dec. places\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pfilter\n",
    "#%pip install ipycanvas\n",
    "# uncomment and run the above if you don't have pfilter and/or ipycanvas installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfilter import ParticleFilter, gaussian_noise, squared_error, independent_sample\n",
    "from scipy.stats import norm, gamma, uniform \n",
    "from particle_tools import FilterCanvas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: probabilistic filters\n",
    "\n",
    "## Outcomes\n",
    "You will understand:\n",
    "* How probabilistic filtering works\n",
    "* How to implement basic probabilistic filters\n",
    "* How filtering can be used to extract hidden states\n",
    "* How to integrate a particle filter into an interactive system\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Goal\n",
    "* Estimate a hidden state in a continuous process from a stream of observations.\n",
    "* Be able to deal with missing or noisy observations.\n",
    "* Be able to project forward into the future as needed.\n",
    "* Be able to quantify uncertainty and the expected value of possible states.\n",
    "\n",
    "## Task\n",
    "We'll build a simple \"swipe\" gesture recogniser. This is intended to recognise a swipe-left or swipe-right movement. Obviously, this is a relatively simple problem to solve, but we'll see how to properly represent uncertainty when approaching it from a Bayesian perspective.\n",
    "\n",
    "<img src=\"imgs/swipe.png\" width=\"50%\">\n",
    "\n",
    "## Process\n",
    "* We build a **filter**, which in this context means a process that combines observations that occur sequentially.\n",
    "* Note: it's not really the same as a filter in the sense of signal processing, though the concept of processing sequential signals is the same.\n",
    "    \n",
    "* The data generating process is assumed to have some temporal coherence; predictions of the future depend on past states.\n",
    "* Typically, we make a *Markov assumption*: that the current unobserved state encodes everything we know about the next state.\n",
    "    \n",
    "### Predictor-corrector\n",
    "\n",
    "The concept is simple: we first build a model that just predicts what we think might be going on -- a pure simulator. Then we can take observations and use them to \"filter out\" predictions that are unrealistic given those observations. This is formulated as a Bayesian belief update.\n",
    "\n",
    "* Prior at time t + evidence at time t -> posterior at time t\n",
    "\n",
    "$$P(X_{t+1}|Y_t, X_t) \\propto P(Y_t | X_{t+1}) P(X_{t+1})$$\n",
    "$$P(X_{t+1}|Y_t, X_t) \\propto P(Y_t | X_{t+1}) P(X_{t})$$\n",
    "\n",
    "* (we don't typically care about normalising this distribution, we just want to track *relative* likelihoods of hypotheses)\n",
    "\n",
    "<img src=\"imgs/stochastic.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package: `pfilter`\n",
    "\n",
    "We'll use the `pfilter` package for this example. This implements a simple interface to a particle filter. *Caveat: I wrote `pfilter`, so my definition of simple may not be everyone's!*\n",
    "\n",
    "### Particle filter\n",
    "A particle filter just represents the current posterior distribution as a collection of samples (definite estimates) and updates them given evidence observed, and a forward model of what evidence *would be expected* for any given sample. It operates in discrete time, feeding the posterior from one step as the prior from the next.\n",
    "\n",
    "We can include dynamics, which specify how the unknown state is believed to be changing over time. Usually, these are *stochastic* dynamics -- they add some diffusion or noise to accommodate the inexact dynamics we implement.\n",
    "\n",
    "Likelihood is implemented by *weighting* samples according to how similar their hypothesised observations are to the true observation. This gives a pseudo-likelihood that is easy to apply.\n",
    "\n",
    "This is a sequential Monte Carlo: we push forward a block of samples through some expected dynamics, compare them to an observation, and reproduce those samples that best approximate the current observation: predict-correct.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Latent variables\n",
    "\n",
    "We need define the variables we want to infer; we'll form distributions over these. We'll stick to a very simple model, which has three variables:\n",
    "\n",
    "* `direction`: + or - for left or right swipe\n",
    "* `phase`: the proportion through the swipe, as a number from 0->1\n",
    "* `phase_rate`: the current rate of movement through the swipe, as a number from 0->1\n",
    "\n",
    "From this, we'll compute a distribution over whether or not a gesture is completed, which we can use to trigger actions. We'll do this by computing the how much evidence there is that the user is at the end of a swipe, with a consistent direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial priors for time t=0\n",
    "We need to set prior distributions on these variables at time t=0. We'll assume we can equally likely be going left or right, and that swipes  start at the beginning (phase close to 0) and have some variable possible rates.\n",
    "\n",
    "* direction: uniform -1, 1\n",
    "* phase: uniform 0, 0.2 (could start just a bit through a swipe)\n",
    "* phase_rate: normal 1, 0.5 (going at a steady rate, with some variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"direction\", \"phase\", \"phase_rate\"]\n",
    "\n",
    "# some basic guesses for how these variables might start out\n",
    "# note: direction is actually -1, 0 or 1, but I've used a continuous\n",
    "# distribution just to make things a bit easier\n",
    "prior_fn = independent_sample([uniform(loc=-1, scale=2).rvs, \n",
    "                                uniform(loc=0.0, scale=0.2).rvs, \n",
    "                                norm(loc=1,scale=0.25).rvs])\n",
    "                               \n",
    "prior_fn(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic model\n",
    "Our filter is applied to a *process* that unfolds over time. The previous timestep posterior is used as the prior for the next timestep. Because we can *predict* what will happen, we can push this posterior through some dynamics to make a better prior for the next timestep.\n",
    "\n",
    "Now we need a model of what would happen in the future *if we had no information about what the user was doing* -- that is, a pure forward simulator. We'll assume that a gesture that is active will continue in the direction it was going, at the same phase rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamics(x):\n",
    "    dt = 0.05\n",
    "    # phase += direction * phase_rate    \n",
    "    x[:,1] = np.tanh(x[:,1] + x[:,2] * dt)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics(prior_fn(10)) # moves forward one timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ParticleFilter(prior_fn=prior_fn, n_particles=100, dynamics_fn=dynamics)        \n",
    "c = FilterCanvas(pf)\n",
    "c.draw()\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion\n",
    "The dynamics we implemented are *deterministic*; they assume that, for example, an initial hypothesis that a gesture is swiping left at 10px per second will continue to behave that way in the future. Given that we know our estimation is uncertain, this is a very strong assumption. A way to ameliorate this is to introduce some **diffusion**: stochastic (random) dynamics, that cause the distribution over latent states to \"spread out\" over time. This is trivial to implement: we just add a bit of noise to each of our particles at each time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(x):\n",
    "    return gaussian_noise(x, sigmas=[0.00, 0.02, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the simulation now, we can see that the particles \"wander\" rather than following straight line paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ParticleFilter(prior_fn=prior_fn, n_particles=100, dynamics_fn=dynamics, noise_fn=noise)        \n",
    "c = FilterCanvas(pf)\n",
    "c.draw()\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation and likelihood\n",
    "\n",
    "So far, we have a forward model that can sample: a data generating process that behaves as we expect the hidden state to behave. We need to implement the *corrector* step, by introducing likelihood. \n",
    "\n",
    "To do this, we introduce observations, and specify a function that tells us: given a hidden (latent) state predict a *definite* hypothesised observation. We can them approximate the (relative) likelihood by comparing each hypothesised observation against the real one, and weighting the result according to how close they are.\n",
    "\n",
    "We'll assume all we can see is the mouse x position at a given instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observe(x):\n",
    "    # return what we *expect* to observe, given the hypotheses we have\n",
    "    direction = np.sign(np.where(np.abs(x[:,0])<0.5, 0, x[:,0]))\n",
    "    return np.where(direction==0, np.random.uniform(-1,1,direction.shape), x[:, 1] * direction)\n",
    "\n",
    "def weight(x, y):\n",
    "    return squared_error(x, y, sigma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ParticleFilter(prior_fn=prior_fn, n_particles=200, dynamics_fn=dynamics, noise_fn=noise, observe_fn=observe,\n",
    "                   weight_fn=weight, resample_proportion=0.01)  \n",
    "pf.update([0.5]) # pass an observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = FilterCanvas(pf, observing=True)\n",
    "c.draw()\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating intention and triggering actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can track *state*; what we want to do is form a distribution over *intention*. We'll apply simple post-processing to\n",
    "the particles to estimate how likely it is we have completed a left or right swipe. We'll just count the number of particles in different states, and use the proportions as our probabilities.\n",
    "\n",
    "This will give us a distribution over `swipe` with three outcomes:\n",
    "\n",
    "* no swipe\n",
    "* left swipe\n",
    "* right swipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_swipe(particles):\n",
    "    # find all particles that have finished, and separate them into left and right\n",
    "    terminated_particles = particles[(particles[:,1]>0.5)]\n",
    "    left_particles = terminated_particles[terminated_particles[:,0]<0]\n",
    "    right_particles = terminated_particles[terminated_particles[:,0]>0]\n",
    "    n_left =len(left_particles)\n",
    "    n_right = len(right_particles)\n",
    "    n_total = len(particles)\n",
    "    n_none = n_total - (n_left+n_right)    \n",
    "    \n",
    "    swipe = {\"left\":n_left/n_total,\n",
    "             \"right\":n_right/n_total,\n",
    "             \"no\":n_none/n_total}\n",
    "    return swipe\n",
    "             \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_swipe(pf.particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ParticleFilter(prior_fn=prior_fn, n_particles=100, dynamics_fn=dynamics, noise_fn=noise, observe_fn=observe,\n",
    "                   weight_fn=weight, resample_proportion=0.01)      \n",
    "c = FilterCanvas(pf, observing=True, estimator=estimate_swipe)\n",
    "c.draw()\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actuation\n",
    "Bayesian interface estimate *beliefs* about state as probability distributions. While this is elegant, it does pose problems when we want to actually do something. \"Doing something\" means making an irreversible change of state. This is the **barrier of action**  -- the barrier that separates movement in belief space from discrete state changes.\n",
    "\n",
    "We need to decide on a decision rule to actuate based on beliefs.\n",
    "\n",
    "The *rational* way to do this is to compute the expected value of each outcome (using some utility function to ascribe a numerical goodness to each action) and choose the action with the highest expected value. In this case, we don't have different values for our actions, so we'll just use the probabilities directly. We'll threshold on the probability of each intention state, and if there is enough evidence, we'll trigger the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_action(swipe):\n",
    "    # we trigger on crossing a probability threshold\n",
    "    # this is not the only choice; we could e.g. use entropy \n",
    "    # to detect a certain state, and select the max. prob. result\n",
    "    p_threshold = 0.75\n",
    "    if swipe[\"left\"]>p_threshold:\n",
    "        return \"left\"\n",
    "    if swipe[\"right\"]>p_threshold:\n",
    "        return \"right\"\n",
    "    return \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ParticleFilter(prior_fn=prior_fn, n_particles=200, dynamics_fn=dynamics, noise_fn=noise, observe_fn=observe,\n",
    "                   weight_fn=weight, resample_proportion=0.05)      \n",
    "c = FilterCanvas(pf, observing=True, estimator=estimate_swipe, trigger=trigger_action)\n",
    "c.draw()\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "One of the major advantages of the particle filtering approach is that we have a generative model which we can *run without data* to make predictions about the future evolution of the system. This can be used to implement **predictive interfaces** which have appropriate uncertainty.\n",
    "\n",
    "All we do is call the particle filter update but decline to provide an observations; the particles are then driven by their internal dynamics alone (like disengaging the clutch in a car and coasting along)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update, but don't provide observations\n",
    "pf.update()\n",
    "pf.update()\n",
    "pf.update()\n",
    "\n",
    "print(pf.particles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = ParticleFilter(prior_fn=prior_fn, n_particles=50, dynamics_fn=dynamics, noise_fn=noise, observe_fn=observe,\n",
    "                   weight_fn=weight, resample_proportion=0.01)      \n",
    "c = FilterCanvas(pf, observing=True, predict=True)\n",
    "c.draw()\n",
    "c.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "### What did we gain?\n",
    "* We were able to track gestures even with not-very-reliable mouse input.\n",
    "* We maintained uncertainty, and could choose to actuate gestures actions when we were quantifiably sure the intention was there.\n",
    "* We could display uncertainty in estimation to the user.\n",
    "* We could also predict the future: this could be useful for display or to reduce apparent latency.\n",
    "### What was difficult?\n",
    "* The filter can be tricky to tune, particularly in weighting the hypothesised sensor values against the real ones\n",
    "* A sample based approach is easy to understand, but isn't the most efficient, and the quality of interaction depends on the sample number.\n",
    "* Any time we are dealing with uncertainty in the loop we have to find ways of reflecting that to the user -- doing so in effectively can be challenging.\n",
    "\n",
    "### What else could we do?\n",
    "* We could obviously extend this to much more complex gestures, or other input devices.\n",
    "* We could use the uncertainty more intelligently in the interaction\n",
    "* We could take better advantage of the fact we don't have to be locked to real-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
