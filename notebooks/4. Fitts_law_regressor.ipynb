{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ACM SIGCHI Summer School on Computational Interaction  \n",
    "Inference, optimization and modeling for the engineering of interactive systems  \n",
    "13th June - 18th June 2022  \n",
    "Saarland University in Saarbr√ºcken, Germany](imgs/header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1DFmcMGfgO6D"
   },
   "source": [
    "# Fitts Law Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e37YcDN_gXGQ"
   },
   "source": [
    "## üîë Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cku272TDgbfo"
   },
   "source": [
    "### üíª Fitts's law\n",
    "\n",
    "In this exercise, we are going to use the key concept from human-interaction  theory - the [Fitts's](https://en.wikipedia.org/wiki/Fitts%27s_law) law.\n",
    "\n",
    "ü§ì ~~Dry~~ theory:\n",
    "\n",
    "Fitts‚Äô law states that the amount of time required for a person to move a pointer (e.g., mouse cursor) to a target area is a function of the distance to the target divided by the size of the target. Thus, the longer the distance and the smaller the target‚Äôs size, the longer it takes.\n",
    "\n",
    "‚õî It is important to mention that constants are always picked manually in the formula below since the problem of computing all possible combinations is [NP-hard](https://en.wikipedia.org/wiki/NP-hardness).\n",
    "\n",
    "üßê Minute of history:\n",
    "\n",
    "In 1954, psychologist Paul Fitts, examining the human motor system, showed that the time required to move to a target depends on the distance to it, yet relates inversely to its size. By his law, fast movements and small targets result in greater error rates, due to the speed-accuracy trade-off. Although multiple variants of Fitts‚Äô law exist, all encompass this idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "OALzG8Jwkung",
    "outputId": "91fd5a49-882a-4636-897e-b1fb847fa803"
   },
   "source": [
    "![fits formula](imgs/fits_formula.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitts' law is applicable to rapid, pointing\n",
    "movements: the longer the distance to a target and the smaller the\n",
    "target size, the longer it takes to reach that target. To actually use\n",
    "this law in practice, HCI researchers must estimate the two constants that\n",
    "depend on the choice of input device, therefore, in this excercise will develop a\n",
    "regression model for computer mice so that they do not have to derive\n",
    "such device-dependent constants anymore.\n",
    "\n",
    "\n",
    "![Fits example](imgs/fit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSq9LDtzmp6v"
   },
   "source": [
    "## 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "4XV56xTBgg2Q",
    "outputId": "8c415a2a-1043-4dfe-f62c-6d9e1027e821"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMl4Ug3tm7Ad"
   },
   "source": [
    "üö© The data contains four key features:\n",
    "* the distance between different points on the screen\n",
    "* width of the screen\n",
    "* id\n",
    "* transition time from one point to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance width id time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13 80 0.217230716220669 104.31569422738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67 73 0.939458458064949 196.15104242622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48 29 1.40880554556733 273.344081725751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44 9 2.55799545312089 445.222458063303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96 41 1.74048007834244 326.544789490528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>96 41 1.74048007834244 304.099924207911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>20 20 1 209.63644102588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>90 46 1.56390088519333 281.754315783647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>75 57 1.21150410519371 239.717689665151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>46 13 2.18220333122075 392.326248102422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      distance width id time\n",
       "0    13 80 0.217230716220669 104.31569422738\n",
       "1    67 73 0.939458458064949 196.15104242622\n",
       "2    48 29 1.40880554556733 273.344081725751\n",
       "3     44 9 2.55799545312089 445.222458063303\n",
       "4    96 41 1.74048007834244 326.544789490528\n",
       "..                                       ...\n",
       "495  96 41 1.74048007834244 304.099924207911\n",
       "496                  20 20 1 209.63644102588\n",
       "497  90 46 1.56390088519333 281.754315783647\n",
       "498  75 57 1.21150410519371 239.717689665151\n",
       "499  46 13 2.18220333122075 392.326248102422\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/fitts-gen.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HS_KTVR9gkmD"
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    X, y = [], []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file, delimiter=' ')\n",
    "        for row in csv_reader:\n",
    "            w, d, t = int(row['width']), int(row['distance']), float(row['time'])\n",
    "            X.append([w, d])\n",
    "            y.append(t)\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/fitts-gen.csv'\n",
    "X,y = load_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VOIlr6i3g26n"
   },
   "source": [
    "## ‚ö°3. Create Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hsmNoVKJnxCY"
   },
   "source": [
    "A neural network with a linear activation function is simply a linear regression model. It has limited power and the ability to handle complexity varying parameters of input data. It takes the inputs, multiplied by the weights for each neuron, and creates an output signal proportional to the input. In one sense, a linear function is better than a step function because it allows multiple outputs, not just yes and no.\n",
    "\n",
    "However, a linear activation function has two major problems:\n",
    "\n",
    "1. Not possible to use [backpropagation](https://en.wikipedia.org/wiki/Backpropagation)  (gradient descent) to train the model‚Äîthe derivative of the function is a constant, and has no relation to the input. So it‚Äôs not possible to go back and understand which weights in the input neurons can provide a better prediction.\n",
    "  \n",
    "2. All layers of the neural network collapse into one‚Äîwith linear activation functions, no matter how many layers in the neural network, the last layer will be a linear function of the first layer (because a linear combination of linear functions is still a linear function). So a linear activation function turns the neural network into just one layer.\n",
    "\n",
    "üîîYou are encouraged to try another activation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLcgXgiNpI37"
   },
   "source": [
    "Here, we use *optimizer='rmsprop'*, but you can try [more](https://keras.io/optimizers/#rmsprop) and compare the results.\n",
    "\n",
    "\n",
    "The MSE, MAE (also RMSE and R-Squared) metrics are mainly used to evaluate the prediction error rates and model performance in regression analysis.\n",
    "\n",
    "* <font color=lightgreen>MAE</font> (Mean absolute error) represents the difference between the original and predicted values extracted by averaged the absolute difference over the data set.\n",
    "\n",
    "* <font color=lightblue>MSE</font> (Mean Squared Error) represents the difference between the original and predicted values extracted by squared the average difference over the data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "colab_type": "code",
    "id": "aYDHaVyXroEr",
    "outputId": "d770154b-7f37-47e4-b9ea-17fc95229a6c"
   },
   "source": [
    "![MAE, MSE](https://econbrowser.com/wp-content/uploads/2019/07/msemae.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dAJRN2YUgsxK"
   },
   "outputs": [],
   "source": [
    "def create_model(dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(dim, activation=\"relu\", input_dim=dim))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mse', optimizer='rmsprop', metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö°4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nCQFX9sDi7og",
    "outputId": "16bdebac-54df-46ab-befa-17b0340d89ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 1s 25ms/step - loss: 69454.3984 - mae: 230.4369 - mse: 69454.3984 - val_loss: 67814.0078 - val_mae: 230.5712 - val_mse: 67814.0078\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 68243.1562 - mae: 227.7488 - mse: 68243.1562 - val_loss: 66797.1562 - val_mae: 228.4351 - val_mse: 66797.1562\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 67242.5938 - mae: 225.5539 - mse: 67242.5938 - val_loss: 65803.8203 - val_mae: 226.3227 - val_mse: 65803.8203\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 66253.5625 - mae: 223.3454 - mse: 66253.5625 - val_loss: 64837.0391 - val_mae: 224.2389 - val_mse: 64837.0391\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65288.0000 - mae: 221.1046 - mse: 65288.0000 - val_loss: 63853.1133 - val_mae: 222.0922 - val_mse: 63853.1133\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64311.1836 - mae: 218.8507 - mse: 64311.1836 - val_loss: 62880.8203 - val_mae: 219.9379 - val_mse: 62880.8203\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 63335.6641 - mae: 216.6102 - mse: 63335.6641 - val_loss: 61911.7109 - val_mae: 217.7534 - val_mse: 61911.7109\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 62361.6016 - mae: 214.2836 - mse: 62361.6016 - val_loss: 60907.4883 - val_mae: 215.4563 - val_mse: 60907.4883\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 61379.5586 - mae: 211.9414 - mse: 61379.5586 - val_loss: 59920.0859 - val_mae: 213.1669 - val_mse: 59920.0859\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 60404.4336 - mae: 209.5369 - mse: 60404.4336 - val_loss: 58926.2812 - val_mae: 210.8116 - val_mse: 58926.2812\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59435.0117 - mae: 207.1084 - mse: 59435.0117 - val_loss: 57929.7383 - val_mae: 208.4104 - val_mse: 57929.7383\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 58466.2852 - mae: 204.6708 - mse: 58466.2852 - val_loss: 56952.0234 - val_mae: 206.0109 - val_mse: 56952.0234\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57508.3516 - mae: 202.2030 - mse: 57508.3516 - val_loss: 55949.0703 - val_mae: 203.5123 - val_mse: 55949.0703\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56532.6250 - mae: 199.6832 - mse: 56532.6250 - val_loss: 54956.0898 - val_mae: 201.0031 - val_mse: 54956.0898\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55564.1445 - mae: 197.1365 - mse: 55564.1445 - val_loss: 53949.0547 - val_mae: 198.4215 - val_mse: 53949.0547\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 54611.6250 - mae: 194.5029 - mse: 54611.6250 - val_loss: 52997.2852 - val_mae: 195.9244 - val_mse: 52997.2852\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53666.3867 - mae: 191.9225 - mse: 53666.3867 - val_loss: 52011.1484 - val_mae: 193.2932 - val_mse: 52011.1484\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 52713.0664 - mae: 189.2350 - mse: 52713.0664 - val_loss: 51039.5469 - val_mae: 190.6391 - val_mse: 51039.5469\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 51772.6836 - mae: 186.5280 - mse: 51772.6836 - val_loss: 50073.3789 - val_mae: 187.9530 - val_mse: 50073.3789\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 50838.8359 - mae: 183.8123 - mse: 50838.8359 - val_loss: 49092.9492 - val_mae: 185.1777 - val_mse: 49092.9492\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49912.1406 - mae: 180.9823 - mse: 49912.1406 - val_loss: 48171.0859 - val_mae: 182.4998 - val_mse: 48171.0859\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49001.0703 - mae: 178.2483 - mse: 49001.0703 - val_loss: 47198.4414 - val_mae: 179.6447 - val_mse: 47198.4414\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48070.3789 - mae: 175.4003 - mse: 48070.3789 - val_loss: 46245.2539 - val_mae: 176.7831 - val_mse: 46245.2539\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47174.6094 - mae: 172.4155 - mse: 47174.6094 - val_loss: 45347.3711 - val_mae: 174.0157 - val_mse: 45347.3711\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46301.9609 - mae: 169.5607 - mse: 46301.9609 - val_loss: 44429.3242 - val_mae: 171.1426 - val_mse: 44429.3242\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 45414.3594 - mae: 166.6543 - mse: 45414.3594 - val_loss: 43510.2305 - val_mae: 168.2057 - val_mse: 43510.2305\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44544.7188 - mae: 163.6381 - mse: 44544.7188 - val_loss: 42623.0898 - val_mae: 165.3016 - val_mse: 42623.0898\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43692.3750 - mae: 160.6875 - mse: 43692.3750 - val_loss: 41718.9531 - val_mae: 162.2903 - val_mse: 41718.9531\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42841.7266 - mae: 157.6726 - mse: 42841.7266 - val_loss: 40854.0000 - val_mae: 159.4336 - val_mse: 40854.0000\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42014.5508 - mae: 154.7068 - mse: 42014.5508 - val_loss: 39983.6836 - val_mae: 156.4897 - val_mse: 39983.6836\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41198.7148 - mae: 151.6574 - mse: 41198.7148 - val_loss: 39145.6719 - val_mae: 153.5774 - val_mse: 39145.6719\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40408.4023 - mae: 148.6442 - mse: 40408.4023 - val_loss: 38315.1562 - val_mae: 150.6230 - val_mse: 38315.1562\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39627.1562 - mae: 145.5854 - mse: 39627.1562 - val_loss: 37512.7344 - val_mae: 147.7663 - val_mse: 37512.7344\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38872.3242 - mae: 142.5782 - mse: 38872.3242 - val_loss: 36718.5000 - val_mae: 144.9823 - val_mse: 36718.5000\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 38128.6055 - mae: 139.7010 - mse: 38128.6055 - val_loss: 35923.2266 - val_mae: 142.1171 - val_mse: 35923.2266\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37386.8672 - mae: 136.9429 - mse: 37386.8672 - val_loss: 35158.0117 - val_mae: 139.2941 - val_mse: 35158.0117\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36677.5820 - mae: 134.4217 - mse: 36677.5820 - val_loss: 34393.9062 - val_mae: 136.4846 - val_mse: 34393.9062\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35989.1914 - mae: 131.8839 - mse: 35989.1914 - val_loss: 33667.4648 - val_mae: 133.8303 - val_mse: 33667.4648\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35324.8984 - mae: 129.6255 - mse: 35324.8984 - val_loss: 32969.1055 - val_mae: 131.2855 - val_mse: 32969.1055\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34675.9414 - mae: 127.2945 - mse: 34675.9414 - val_loss: 32261.1543 - val_mae: 128.7371 - val_mse: 32261.1543\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 34045.4688 - mae: 125.1251 - mse: 34045.4688 - val_loss: 31619.6367 - val_mae: 126.6510 - val_mse: 31619.6367\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 33449.4336 - mae: 123.2378 - mse: 33449.4336 - val_loss: 30959.9824 - val_mae: 124.5756 - val_mse: 30959.9824\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32880.0859 - mae: 121.4236 - mse: 32880.0859 - val_loss: 30364.9551 - val_mae: 122.7751 - val_mse: 30364.9551\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32338.2305 - mae: 119.7961 - mse: 32338.2305 - val_loss: 29775.4395 - val_mae: 121.1134 - val_mse: 29775.4395\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31813.6797 - mae: 118.2802 - mse: 31813.6797 - val_loss: 29189.5605 - val_mae: 119.4923 - val_mse: 29189.5605\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31316.3945 - mae: 116.8342 - mse: 31316.3945 - val_loss: 28647.2949 - val_mae: 117.9785 - val_mse: 28647.2949\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 30826.9375 - mae: 115.6177 - mse: 30826.9375 - val_loss: 28093.1777 - val_mae: 116.5880 - val_mse: 28093.1777\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30379.7051 - mae: 114.6611 - mse: 30379.7051 - val_loss: 27630.2422 - val_mae: 115.7124 - val_mse: 27630.2422\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29965.1992 - mae: 113.7773 - mse: 29965.1992 - val_loss: 27142.5293 - val_mae: 114.9753 - val_mse: 27142.5293\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29567.6934 - mae: 113.1399 - mse: 29567.6934 - val_loss: 26719.6191 - val_mae: 114.3370 - val_mse: 26719.6191\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29199.3203 - mae: 112.6289 - mse: 29199.3203 - val_loss: 26269.5020 - val_mae: 113.6236 - val_mse: 26269.5020\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28842.5293 - mae: 112.2231 - mse: 28842.5293 - val_loss: 25876.8379 - val_mae: 112.9667 - val_mse: 25876.8379\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28528.1406 - mae: 111.9677 - mse: 28528.1406 - val_loss: 25498.8105 - val_mae: 112.3114 - val_mse: 25498.8105\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 28228.0508 - mae: 111.7260 - mse: 28228.0508 - val_loss: 25156.0703 - val_mae: 111.6956 - val_mse: 25156.0703\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27965.6191 - mae: 111.4836 - mse: 27965.6191 - val_loss: 24868.5293 - val_mae: 111.1664 - val_mse: 24868.5293\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27723.1855 - mae: 111.2419 - mse: 27723.1855 - val_loss: 24567.2383 - val_mae: 110.6064 - val_mse: 24567.2383\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27472.2793 - mae: 111.1423 - mse: 27472.2793 - val_loss: 24277.8066 - val_mae: 110.0558 - val_mse: 24277.8066\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27244.9531 - mae: 110.8750 - mse: 27244.9531 - val_loss: 23988.8066 - val_mae: 109.4906 - val_mse: 23988.8066\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27015.2109 - mae: 110.7136 - mse: 27015.2109 - val_loss: 23727.9707 - val_mae: 109.0063 - val_mse: 23727.9707\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26790.0176 - mae: 110.5528 - mse: 26790.0176 - val_loss: 23449.3145 - val_mae: 108.5099 - val_mse: 23449.3145\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26562.6992 - mae: 110.3398 - mse: 26562.6992 - val_loss: 23175.0566 - val_mae: 108.0414 - val_mse: 23175.0566\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26368.8652 - mae: 110.3626 - mse: 26368.8652 - val_loss: 22972.5020 - val_mae: 107.7283 - val_mse: 22972.5020\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26198.2344 - mae: 110.2222 - mse: 26198.2344 - val_loss: 22760.4824 - val_mae: 107.3912 - val_mse: 22760.4824\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26024.9395 - mae: 110.1599 - mse: 26024.9395 - val_loss: 22543.4941 - val_mae: 107.0345 - val_mse: 22543.4941\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25863.8066 - mae: 110.0987 - mse: 25863.8066 - val_loss: 22376.3770 - val_mae: 106.7560 - val_mse: 22376.3770\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25723.3027 - mae: 110.0292 - mse: 25723.3027 - val_loss: 22202.9492 - val_mae: 106.4828 - val_mse: 22202.9492\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25576.7695 - mae: 110.0595 - mse: 25576.7695 - val_loss: 22029.1328 - val_mae: 106.2035 - val_mse: 22029.1328\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25430.6992 - mae: 109.9710 - mse: 25430.6992 - val_loss: 21852.5898 - val_mae: 105.9135 - val_mse: 21852.5898\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25280.2559 - mae: 109.9359 - mse: 25280.2559 - val_loss: 21668.1152 - val_mae: 105.6022 - val_mse: 21668.1152\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25145.4883 - mae: 109.9604 - mse: 25145.4883 - val_loss: 21540.8047 - val_mae: 105.3879 - val_mse: 21540.8047\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25030.7383 - mae: 109.8135 - mse: 25030.7383 - val_loss: 21379.0781 - val_mae: 105.1029 - val_mse: 21379.0781\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24901.7227 - mae: 109.7983 - mse: 24901.7227 - val_loss: 21232.0566 - val_mae: 104.8430 - val_mse: 21232.0566\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24776.7383 - mae: 109.7546 - mse: 24776.7383 - val_loss: 21089.1191 - val_mae: 104.5881 - val_mse: 21089.1191\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24647.6055 - mae: 109.7230 - mse: 24647.6055 - val_loss: 20916.2969 - val_mae: 104.2609 - val_mse: 20916.2969\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24514.5879 - mae: 109.7674 - mse: 24514.5879 - val_loss: 20762.1113 - val_mae: 103.9711 - val_mse: 20762.1113\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24397.4883 - mae: 109.6847 - mse: 24397.4883 - val_loss: 20638.7031 - val_mae: 103.7373 - val_mse: 20638.7031\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24294.0742 - mae: 109.6399 - mse: 24294.0742 - val_loss: 20516.5371 - val_mae: 103.5042 - val_mse: 20516.5371\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24186.5176 - mae: 109.6376 - mse: 24186.5176 - val_loss: 20409.2168 - val_mae: 103.3105 - val_mse: 20409.2168\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24085.4258 - mae: 109.4477 - mse: 24085.4258 - val_loss: 20278.5859 - val_mae: 103.0867 - val_mse: 20278.5859\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23979.0684 - mae: 109.4501 - mse: 23979.0684 - val_loss: 20168.4707 - val_mae: 102.9078 - val_mse: 20168.4707\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 23868.1992 - mae: 109.2992 - mse: 23868.1992 - val_loss: 20022.7695 - val_mae: 102.6737 - val_mse: 20022.7695\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23772.1777 - mae: 109.2915 - mse: 23772.1777 - val_loss: 19928.0996 - val_mae: 102.5344 - val_mse: 19928.0996\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23672.6875 - mae: 109.3235 - mse: 23672.6875 - val_loss: 19830.6426 - val_mae: 102.3913 - val_mse: 19830.6426\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23582.3496 - mae: 109.1906 - mse: 23582.3496 - val_loss: 19733.4180 - val_mae: 102.2391 - val_mse: 19733.4180\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23498.4141 - mae: 109.1784 - mse: 23498.4141 - val_loss: 19630.5312 - val_mae: 102.0741 - val_mse: 19630.5312\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step - loss: 23412.6074 - mae: 109.0869 - mse: 23412.6074 - val_loss: 19541.1953 - val_mae: 101.9279 - val_mse: 19541.1953\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23327.7402 - mae: 109.1180 - mse: 23327.7402 - val_loss: 19439.0605 - val_mae: 101.7828 - val_mse: 19439.0605\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23242.6230 - mae: 109.0686 - mse: 23242.6230 - val_loss: 19348.5234 - val_mae: 101.6666 - val_mse: 19348.5234\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23154.1016 - mae: 109.0480 - mse: 23154.1016 - val_loss: 19260.7656 - val_mae: 101.5500 - val_mse: 19260.7656\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 23075.2422 - mae: 108.9350 - mse: 23075.2422 - val_loss: 19177.5195 - val_mae: 101.4405 - val_mse: 19177.5195\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22998.4004 - mae: 108.8829 - mse: 22998.4004 - val_loss: 19095.1680 - val_mae: 101.3302 - val_mse: 19095.1680\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22923.1777 - mae: 108.9462 - mse: 22923.1777 - val_loss: 19017.7637 - val_mae: 101.2340 - val_mse: 19017.7637\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22853.6270 - mae: 108.8146 - mse: 22853.6270 - val_loss: 18949.8359 - val_mae: 101.1542 - val_mse: 18949.8359\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22780.2773 - mae: 108.8376 - mse: 22780.2773 - val_loss: 18871.0703 - val_mae: 101.1003 - val_mse: 18871.0703\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22703.2578 - mae: 108.8395 - mse: 22703.2578 - val_loss: 18795.4180 - val_mae: 101.0629 - val_mse: 18795.4180\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22641.4922 - mae: 108.7408 - mse: 22641.4922 - val_loss: 18737.8477 - val_mae: 101.0356 - val_mse: 18737.8477\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22576.2969 - mae: 108.6601 - mse: 22576.2969 - val_loss: 18672.3848 - val_mae: 101.0197 - val_mse: 18672.3848\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22517.8828 - mae: 108.6775 - mse: 22517.8828 - val_loss: 18618.1836 - val_mae: 101.0168 - val_mse: 18618.1836\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22457.3027 - mae: 108.6272 - mse: 22457.3027 - val_loss: 18553.6016 - val_mae: 101.0210 - val_mse: 18553.6016\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22399.4492 - mae: 108.5986 - mse: 22399.4492 - val_loss: 18504.4395 - val_mae: 101.0260 - val_mse: 18504.4395\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 18504.4395 - mae: 101.0260 - mse: 18504.4395\n",
      "MAE: 101.03, MSE: 18504.44\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "    # Create partitions.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "    # Set callbacks, for monitoring progress.\n",
    "    cb_tensorboard = TensorBoard(log_dir='/tmp/fitts_logs')\n",
    "    cb_earlystopping = EarlyStopping(patience=20)\n",
    "\n",
    "    # Train the model.\n",
    "    model = create_model(X_train.shape[1])\n",
    "    print(model.summary())\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        callbacks=[cb_tensorboard, cb_earlystopping]\n",
    "    )\n",
    "\n",
    "    # Evaluate the model.\n",
    "    loss, mae, mse = model.evaluate(X_test, y_test)\n",
    "    print('MAE: {:.2f}, MSE: {:.2f}'.format(mae, mse))\n",
    "\n",
    "    # Save the model.\n",
    "    model.save('Models/fitts_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-gY-n_pzg-Q3"
   },
   "source": [
    "## üíé 5. Model testing\n",
    "\n",
    "<font color=green>R-Squared</font> (Coefficient of determination) represents the coefficient of how well the values fit compared to the original values. Usually, the value from 0 to 1 if there no additional constraints. The higher the value is, the better the model is. You can see an adjusted version of R-Squared in the Figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "mNzQcZgvuBXD",
    "outputId": "ceacf93d-ee53-4e08-b0bf-486a67a2d42e"
   },
   "source": [
    "![Rsq](https://i.stack.imgur.com/xb1VY.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qbl95pCsuAwG"
   },
   "source": [
    "[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) transforms features by scaling each feature to a given range.\n",
    "\n",
    "This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one. You will find a simple example of using this technique below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hfd9jpnMtd_r"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras import models \n",
    "#from fitts_train import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "IbwGLXU6k8FN",
    "outputId": "9c58bdd7-b14c-455a-a00b-b2b6c52cd7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: -0.050334897879442675\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_file = 'data/fitts-gen.csv'\n",
    "X, y = load_dataset(dataset_file)\n",
    "\n",
    "\n",
    "# Create partitions.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "model = models.load_model('Models/fitts_model.h5', compile=False)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the quality of the fit.\n",
    "print('R-squared:', r2_score(y_test, y_pred))\n",
    "\n",
    "# Plot predictions against ground-truth.\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis('square')\n",
    "# Add some padding to the plot so that all the data can fit in well.\n",
    "max_val = 1.1 * max(y_test.max(), y_pred.max())\n",
    "plt.xlim([0, max_val])\n",
    "plt.ylim([0, max_val])\n",
    "# Add a diagonal line to appreciate better the predictions.\n",
    "plt.plot([0, max_val], [0, max_val], color='gray')\n",
    "plt.scatter(y_test, y_pred)\n",
    "# Save as PNG file and display plot.\n",
    "plt.savefig('{}.png'.format(dataset_file))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Gsdpb96yzMJ"
   },
   "source": [
    "üÜò As you can see R-Squared is negative. You might wonder at this point, how it can be negative?\n",
    "\n",
    "In fact, R-Squared compares the fit of the chosen model with that of a horizontal straight line (the null hypothesis). If the chosen model fits worse than a horizontal line, then R-Squared is negative. Note that R-Squared is not always the square of anything, so it can have a negative value without violating any rules of math. R-Squared is negative only when the chosen model does not follow the trend of the data, so fits worse than a horizontal line.\n",
    "\n",
    "üí° To sum up, a <font color=red>negative R-Squared</font> is not a mathematical impossibility or the sign of a bug. It simply means that the chosen model (with its constraints) fits the data really poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAS-CpF5iLoa"
   },
   "source": [
    "## üèÅ 6. Conclusion\n",
    "\n",
    "Now, you know:\n",
    "\n",
    "1.   How to apply linear model according to Fitt's law.\n",
    "2.   How to scale the data using MinMaxScaler from Sk-learn.\n",
    "3.   How to use different regression metrics and how to interpret them.\n",
    "3.   How to work with different parameters of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Fitts_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
