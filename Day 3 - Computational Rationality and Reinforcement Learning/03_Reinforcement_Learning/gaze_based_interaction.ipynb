{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fitted-component",
   "metadata": {
    "id": "fitted-component"
   },
   "source": [
    "# Computationally rational gaze-based interaction\n",
    "\n",
    "Andrew Howes & Xiuli Chen\n",
    "\n",
    "University of Birmingham<br>\n",
    "Aalto University<br>\n",
    "\n",
    "The purpose of this tutorial is to introduce an approach to building computationally rational models.\n",
    "\n",
    "It does the following:\n",
    "\n",
    "* imports libraries,\n",
    "* defines a cognitive POMDP for computational rationality,\n",
    "* defines a theory of gaze based interaction as a cognitive POMDP,\n",
    "* defines the external environment (the task),\n",
    "* combines the theory and external environment into a machine learning problem (a model) that can be solved with baselines3,\n",
    "* train the model,\n",
    "* examines the learning curve to ensure that we are generating an approximately optimal policy,\n",
    "* animates the model behaviour to develop our intuitions about its adaptation,\n",
    "* compares the model to human data.\n",
    "\n",
    "Preqrequisites:\n",
    "\n",
    "* foveated vision\n",
    "* Bayesian integration\n",
    "* POMDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vL8yMY6q_Rd-",
   "metadata": {
    "id": "vL8yMY6q_Rd-"
   },
   "outputs": [],
   "source": [
    "# Install baselines3\n",
    "# Only needs to be run once\n",
    "\n",
    "#!pip install stable_baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oeJU5wJR7A8V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1652,
     "status": "ok",
     "timestamp": 1643210006123,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "oeJU5wJR7A8V",
    "outputId": "f8e53d98-820c-4a31-b9f5-e4b5c46bd72b"
   },
   "outputs": [],
   "source": [
    "# This cell only for users of Google Colab.\n",
    "# No need to run this if you are using Jupyter notebooks\n",
    "# Mount Google drive and change directory into the project folder\n",
    "# Only needs to be run once\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#%cd '/content/drive/MyDrive/CHI22CMT/CHI22_CogMod_Tutorial/03-Reinforcement-Learning/034_Gaze_based_Interaction'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-point",
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1643209000116,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "obvious-point"
   },
   "outputs": [],
   "source": [
    "# load required standard modules and configure matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P44tljjb8hBC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6305,
     "status": "ok",
     "timestamp": 1643209694066,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "P44tljjb8hBC",
    "outputId": "d635fb70-1df0-4ab3-f15e-13b3d7b2fdc9"
   },
   "outputs": [],
   "source": [
    "# Load local modules\n",
    "# gazetools is a module that contains functions for modeling gaze-based interaction.\n",
    "\n",
    "from gazetools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-leadership",
   "metadata": {
    "id": "injured-leadership"
   },
   "source": [
    "### A Cognitive POMDP\n",
    "\n",
    "<img src=\"image/cognitive_POMDP.png\" alt=\"Box diagram of a cognitive model.\" width=\"300\" height=\"400\">\n",
    "\n",
    "A cognitive POMDP is a framework for specifying cognitive models.\n",
    "\n",
    "The first step to formalise this framework is to define the architecture of the model. We do this by specifying a class of cognitive theories and will later define instances of this class.\n",
    "\n",
    "The class has only a single method, which defines a step through the processes defined in the figure. \n",
    "\n",
    "All processes and variables are defined except the agent and its policy! We will show later how to learn the policy with reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-ivory",
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1643209727593,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "monetary-ivory"
   },
   "outputs": [],
   "source": [
    "class CognitivePOMDP():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.internal_state = {}\n",
    "        \n",
    "    def step(self, ext, action):\n",
    "        ''' Define the cognitive POMDP.'''\n",
    "        self._update_state_with_action(action)\n",
    "        response = self._get_response()\n",
    "        external_state, done = ext.external_env(response)\n",
    "        stimulus, stimulus_std = self._get_stimulus(ext.external_state)\n",
    "        self._update_state_with_stimulus(stimulus, stimulus_std)\n",
    "        obs = self._get_obs()\n",
    "        reward = self._get_reward()\n",
    "        return obs, reward, done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-timeline",
   "metadata": {
    "id": "brazilian-timeline"
   },
   "source": [
    "### A theory of gaze-based interaction\n",
    "\n",
    "Each of the entities in CognitivePOMDP must be defined so as to state our theory of gaze-based interaction. The theory makes the following assumptions:\n",
    "\n",
    "* Target location stimuli are corrupted by Gaussian noise in human vision.\n",
    "* The standard deviation of noise increases linearly with eccentricity from the fovea.\n",
    "* Sequences of stimuli are noisily perceived and optimally integrated.\n",
    "* Intended eye movements (oculomotor actions) are corrupted by signal dependent Gaussian noise to generate responses.\n",
    "\n",
    "These assumptions are further described in Chen et al. (2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-reunion",
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1643209731182,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "accepted-reunion"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GazeTheory(CognitivePOMDP):\n",
    "\n",
    "    def __init__(self):\n",
    "        ''' Initialise the theoretically motivated parameters.'''\n",
    "        # weight eye movement noise with distance of saccade\n",
    "        self.oculamotor_noise_weight = 0.01\n",
    "        # weight noise with eccentricity\n",
    "        self.stimulus_noise_weight = 0.09\n",
    "        # step_cost for the reward function\n",
    "        self.step_cost = -1\n",
    "        # super.__init__()\n",
    "\n",
    "    def reset_internal_env(self, external_state):\n",
    "        ''' The internal state includes the fixation location, the latest estimate of \n",
    "        the target location and the target uncertainty. Assumes that there is no \n",
    "        uncertainty in the fixation location.\n",
    "        Assumes that width is known. All numbers are on scale -1 to 1.\n",
    "        The target_std represents the strength of the prior.'''\n",
    "        self.internal_state = {'fixation': np.array([-1,-1]),  \n",
    "                               'target': np.array([0,0]), \n",
    "                               'target_std': 0.1,\n",
    "                               'width': external_state['width'],\n",
    "                               'action': np.array([-1,-1])} \n",
    "        return self._get_obs()    \n",
    "\n",
    "    def _update_state_with_action(self, action):\n",
    "        self.internal_state['action'] = action\n",
    "        \n",
    "    def _get_response(self):\n",
    "        ''' Take an action and add noise.'''\n",
    "        # !!!! should take internal_state as parameter\n",
    "        move_distance = get_distance( self.internal_state['fixation'], \n",
    "                                     self.internal_state['action'] )\n",
    "        \n",
    "        ocularmotor_noise = np.random.normal(0, self.oculamotor_noise_weight * move_distance, \n",
    "                                        self.internal_state['action'].shape)\n",
    "        # response is action plus noise\n",
    "        response = self.internal_state['action'] + ocularmotor_noise\n",
    "        \n",
    "        # update the ocularmotor state (internal)\n",
    "        self.internal_state['fixation'] = response\n",
    "        \n",
    "        # make an adjustment if response is out of range. \n",
    "        response = np.clip(response,-1,1)\n",
    "        return response\n",
    "    \n",
    "    def _get_stimulus(self, external_state):\n",
    "        ''' define a psychologically plausible stimulus function in which acuity \n",
    "        falls off with eccentricity.''' \n",
    "        eccentricity = get_distance( external_state['target'], external_state['fixation'] )\n",
    "        stm_std = self.stimulus_noise_weight * eccentricity\n",
    "        stimulus_noise = np.random.normal(0, stm_std, \n",
    "                                         external_state['target'].shape)\n",
    "        # stimulus is the external target location plus noise\n",
    "        stm = external_state['target'] + stimulus_noise\n",
    "        return stm, stm_std\n",
    "\n",
    "    \n",
    "    def _update_state_with_stimulus(self, stimulus, stimulus_std):\n",
    "        posterior, posterior_std = self.bayes_update(stimulus, \n",
    "                                                     stimulus_std, \n",
    "                                                     self.internal_state['target'],\n",
    "                                                     self.internal_state['target_std'])\n",
    "        self.internal_state['target'] = posterior\n",
    "        self.internal_state['target_std'] = posterior_std\n",
    "\n",
    "    def bayes_update(self, stimulus, stimulus_std, belief, belief_std):\n",
    "        ''' A Bayes optimal function that integrates multiple stimuluss.\n",
    "        The belief is the prior.'''\n",
    "        z1, sigma1 = stimulus, stimulus_std\n",
    "        z2, sigma2 = belief, belief_std\n",
    "        w1 = sigma2**2 / (sigma1**2 + sigma2**2)\n",
    "        w2 = sigma1**2 / (sigma1**2 + sigma2**2)\n",
    "        posterior = w1*z1 + w2*z2\n",
    "        posterior_std = np.sqrt( (sigma1**2 * sigma2**2)/(sigma1**2 + sigma2**2) )\n",
    "        return posterior, posterior_std\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        # the Bayesian posterior has already been calculated so just return it.\n",
    "        # could also return the target_std so that the controller knows the uncertainty \n",
    "        # of the observation.\n",
    "        #return self.internal_state['target']\n",
    "        return np.array([self.internal_state['target'][0],\n",
    "                        self.internal_state['target'][1],\n",
    "                        self.internal_state['target_std']])\n",
    "    \n",
    "    def _get_reward(self):\n",
    "        distance = get_distance(self.internal_state['fixation'], \n",
    "                                self.internal_state['target'])\n",
    "        \n",
    "        if distance < self.internal_state['width'] / 2:\n",
    "            reward = 0\n",
    "        else:\n",
    "            reward = -distance # a much better model of the psychological reward function is possible.\n",
    "            \n",
    "        return reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-missile",
   "metadata": {
    "id": "boolean-missile"
   },
   "source": [
    "### External environment\n",
    "\n",
    "In order to test the theory we need to define the external environment. \n",
    "\n",
    "The external environment allows us to make predictions from the theory for a particular task. The theory makes predictions for many more tasks. For example, adaptation to mixed target widths and distances.\n",
    "\n",
    "Note, the external environment is a type of auxiliary assumption. Auxiliary assumptions must not be \"auxiliary hypothesis\". See Gershman (2019) https://link.springer.com/article/10.3758/s13423-018-1488-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-archives",
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1643209742334,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "bacterial-archives"
   },
   "outputs": [],
   "source": [
    "class GazeTask():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.target_width = 0.15\n",
    "        self.target_loc_std = 0.3\n",
    "\n",
    "    def reset_external_env(self):\n",
    "        ''' The external_state includes the fixation and target location.\n",
    "        Choose a new target location and reset to the first fixation location.'''\n",
    "        \n",
    "        def _get_new_target():\n",
    "            x_target =np.clip(np.random.normal(0, self.target_loc_std),-1,1)\n",
    "            y_target =np.clip(np.random.normal(0, self.target_loc_std),-1,1)         \n",
    "            return np.array( [x_target, y_target] )\n",
    "    \n",
    "        fx = np.array([-1,-1])\n",
    "        tg = _get_new_target()\n",
    "        self.external_state = {'fixation':fx, 'target':tg, 'width':self.target_width }\n",
    "    \n",
    "    def external_env(self, action):\n",
    "        self.external_state['fixation'] = action\n",
    "        \n",
    "        # determine when the goal has been achieved.\n",
    "        distance = get_distance(self.external_state['fixation'], \n",
    "                                self.external_state['target'])\n",
    "        if distance < self.external_state['width']/2 :\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        return self.external_state, done\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-alliance",
   "metadata": {
    "id": "combined-alliance"
   },
   "source": [
    "### Gym environment\n",
    "\n",
    "In order to find an optimal policy we use the theory and external environment to define a machine learning problem, here, making use of the framework defined by one specific library called gym.\n",
    "\n",
    "For further information see: https://gym.openai.com/\n",
    "\n",
    "gym.Env is a class provided by this library. Note that Env here refers to all of the components of the, including both internal and external environment, with the exception of the controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-sleeve",
   "metadata": {
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1643209749681,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "applicable-sleeve"
   },
   "outputs": [],
   "source": [
    "class GazeModel(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        def default_box(x):\n",
    "            return spaces.Box(low=-1, high=1, shape=(x, ), dtype=np.float64)\n",
    "        \n",
    "        self.GT = GazeTheory()\n",
    "        self.TX = GazeTask()        \n",
    "        \n",
    "        # Required by gym. These define the range of each variable.\n",
    "        # Each action has an x,y coordinate therefore the box size is 2.\n",
    "        # Each obs has a an x,y and an uncertainty therefore the box size is 3.\n",
    "        self.action_space = default_box(2)\n",
    "        self.observation_space = default_box(3)\n",
    "        \n",
    "        # max_fixations per episode. Used to curtail exploration early in training.\n",
    "        self.max_steps = 500\n",
    "        \n",
    "    def reset(self):\n",
    "        self.n_step = 0\n",
    "        self.TX.reset_external_env()\n",
    "        self.GT.reset_internal_env(self.TX.external_state)\n",
    "        obs = self.GT.reset_internal_env( self.TX.external_state )\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        obs, reward, done = self.GT.step( self.TX, action )\n",
    "        self.n_step+=1\n",
    "\n",
    "        # give up if been looking for too long\n",
    "        if self.n_step > self.max_steps:\n",
    "            done = True\n",
    "        \n",
    "        info = self.get_info()\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def get_info(self):\n",
    "        return {'step': self.n_step,\n",
    "                'target_width': self.TX.target_width,\n",
    "                'target_x': self.TX.external_state['target'][0],\n",
    "                'target_y': self.TX.external_state['target'][1],\n",
    "                'fixate_x':self.TX.external_state['fixation'][0],\n",
    "                'fixate_y':self.TX.external_state['fixation'][1] }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-covering",
   "metadata": {
    "id": "complex-covering"
   },
   "source": [
    "### Test the model\n",
    "\n",
    "Step through the untrained model to check for simple bugs. More comprehensive tests needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed00048",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 534,
     "status": "ok",
     "timestamp": 1643209756680,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "4ed00048",
    "outputId": "95f13fd2-30ad-43d9-8cab-1d127f6359d6"
   },
   "outputs": [],
   "source": [
    "model = GazeModel()\n",
    "\n",
    "model.reset()\n",
    "\n",
    "i=0\n",
    "done = False\n",
    "while not done:\n",
    "    # make a step with a randomly sampled action\n",
    "    obs, reward, done, info = model.step(model.action_space.sample())\n",
    "    i+=1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-stevens",
   "metadata": {
    "id": "cognitive-stevens"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "We can train the model to generate a controller.\n",
    "\n",
    "By plotting the learning curve we can see whether the performance improves with training and whether the model approaches an optimum performance. We are interested in approximately optimal performance, so if the training curve is not approaching asymptote then we need to train with more timesteps or revise the model.\n",
    "\n",
    "We can see that at first the model uses hundreds of fixations to find the target, this is because it has not yet learned to move the gaze in a way that is informed by the observation. As it learns to do this, it takes fewer steps to gaze at the target and its performance improves.\n",
    "\n",
    "If our problem definition is correct then the model will get more 'human-like' the more that it is trained. In other words, training makes it a better model of interaction.\n",
    "\n",
    "If we assume that people are computationally rational then the optimal solution to a cognitive problem predicts human behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0910ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 66705,
     "status": "ok",
     "timestamp": 1643209827031,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "7d0910ac",
    "outputId": "d927873a-e745-4931-d6b8-fb6f3a668245"
   },
   "outputs": [],
   "source": [
    "timesteps = 200000\n",
    "#timesteps = 50000\n",
    "\n",
    "controller = train(model, timesteps)\n",
    "plot_learning_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-georgia",
   "metadata": {
    "id": "japanese-georgia"
   },
   "source": [
    "### Run the model\n",
    "Run the trained model and save a trace of each episode to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-evans",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 162308,
     "status": "ok",
     "timestamp": 1643210003598,
     "user": {
      "displayName": "Andrew Howes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GguyjUymXH2ndqd0p8hhQuI6UyIwWtm4lsMYWs0Ug=s64",
      "userId": "02694399383679444060"
     },
     "user_tz": 0
    },
    "id": "after-evans",
    "outputId": "838f8f2b-9414-454a-8700-acfd39062bb8"
   },
   "outputs": [],
   "source": [
    "run_model( model, controller, 100, 'behaviour_trace.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-capture",
   "metadata": {
    "id": "stable-capture"
   },
   "source": [
    "### Next\n",
    "\n",
    "Go to notebook 'visualise'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-headquarters",
   "metadata": {
    "id": "weekly-headquarters"
   },
   "source": [
    "### References\n",
    "Chen, X., Acharya, A., Oulasvirta, A., & Howes, A. (2021, May). An adaptive model of gaze-based selection. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1-11)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gaze-based-interaction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
