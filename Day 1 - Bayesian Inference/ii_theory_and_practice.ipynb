{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pprint import pprint\n",
    "\n",
    "# set some styling defaults for matplotlib\n",
    "plt.style.use(\"seaborn-talk\")\n",
    "mpl.rcParams[\"figure.dpi\"] = 90  # change this to set apparent figure size\n",
    "mpl.rcParams[\"figure.figsize\"] = (10, 4)\n",
    "mpl.rcParams[\"figure.frameon\"] = False\n",
    "\n",
    "# set decimal precision to 3 dec. places\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II: Theory and practice\n",
    "\n",
    "**sli.do** https://app.sli.do/event/qz3PTe61RKpcryL6xGCDUS\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "You will understand:\n",
    "\n",
    "* What a Bayesian is.\n",
    "* The idea of a data generating process;\n",
    "* The relation of models and parameters;\n",
    "* What uncertainty is, where it comes from, and why it is important;\n",
    "* What probability is and how it represents uncertainty;\n",
    "* The distinction between prediction and inference and the relation to forward and inverse probability.\n",
    "* A high-speed review of basic probability theory through code: \n",
    "    * axioms of probability\n",
    "    * mass functions, distributions, random variables\n",
    "    * likelihood and sampling\n",
    "    * joint, marginal, conditional, Bayes' rule\n",
    "    * entropy, divergence\n",
    "* Major classes of Bayesian inference algorithms\n",
    "\n",
    "### Survey results\n",
    "<img src=\"imgs/survey_prob.png\">\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "## What is a Bayesian [I]?\n",
    "\n",
    "### Poll\n",
    "\n",
    "What does being a Bayesian mean to you, right now?\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"imgs/facets.png\" width=\"30%\">\n",
    "\n",
    "A Bayesian is someone who:\n",
    "\n",
    "* Is happy to live without truth;\n",
    "* Reasons from belief to belief, guided by evidence;\n",
    "* Thinks backwards by thinking forwards.\n",
    "\n",
    "### Without truth\n",
    "We might be used to computations that deal in absolute truths, but these aren't that useful for modelling. Very few processes are sufficiently stable and sufficiently well-understood that\n",
    "they can be precisely modelled without uncertainty. Only being capable of dealing in absolute truths is exceedingly limiting; it breeds fragility and irrationality. \n",
    "\n",
    "### Belief to belief\n",
    "A Bayesian computation does not result in a change of *state*, but a change of beliefs. This originates from some original beliefs and is then adjusted to be compatible with evidence that has been observed. This evidence typically concentrates belief on a tighter set of possible configurations. \n",
    "\n",
    "### Forwards, not back\n",
    "Bayesian modelling involves first modelling *what we might observe given a hypothesis* and not *what hypothesis to choose given an observation*. This is a very important distinction, and makes it trivial to combine evidence from multiple sources.\n",
    "\n",
    "\n",
    "# Models\n",
    "Let's get back to computational interaction. A tenet of the approach is that it puts models *first*. Every model in computational interaction will be a bit of code that is executed in order to gain insight into an interaction phenomena that we cannot directly access. Not all things that are called models are equivalent, however. We need to think about the characteristics that of models of interaction: are some better than others?\n",
    "\n",
    "## On the virtues of models\n",
    "Given two models that model some interaction phenomena equally well, we'd prefer the model that:\n",
    "\n",
    "* is easily implemented computationally and fits with software engineering practices;\n",
    "* is conveniently parameterised, with *interpretable* parameters;\n",
    "* is generative, and expressed in terms of generating synthetic observations;\n",
    "* is capable of propagating uncertainty correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generating processes\n",
    " We need *models* to do *computational interaction*, and they need to be *executable*. We'd further like them to be *generative*. That implies code that simulates or emulates some part of an interactive system -- a **forward model** that transforms unknown states into the observable quantities they imply. At the heart of Bayesian modelling we have the idea of a **data generating process**, a process which we believe is generating data we observe. We implement this as an algorithm\n",
    "which generates synthetic observations. \n",
    "\n",
    "> This is just a function!\n",
    "\n",
    "\n",
    "Every application of Bayesian ideas starts with the data generating process: write down code that will spit out plausible simulations, given some configurable parameters.\n",
    "\n",
    "\n",
    "\n",
    "### A very simple example\n",
    "Let's model how tall someone is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm_1():\n",
    "    return 180.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That isn't a very inspiring model, but it is a computational model that we can execute. A better model would be parametric (i.e. takes parameters).\n",
    "\n",
    "### Parameters\n",
    "\n",
    "These are just the things that we can vary to change the result (i.e. parameters we pass in to the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm_2(gender):\n",
    "    if gender==\"male\":\n",
    "        return 175\n",
    "    if gender==\"female\":\n",
    "        return 162            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_2(\"male\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or multiple parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_tall_cm_3(gender, age):\n",
    "    if gender == \"male\":\n",
    "        return 85 + min(age, 16) * 5.63\n",
    "    if gender==\"female\":\n",
    "        return 80 + min(age, 16) * 5.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_3(\"female\", 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Higher-level parameters\n",
    "\n",
    "We can have higher-level parameters, where the model includes parameters that determine other parameters or the relationships between them. Sometimes we will have a mixture of *observed* values and *latent* (hidden) parameters; but this poses no problem in modelling. \n",
    "\n",
    "We often write things like $$y = f(x;\\theta)$$ to mean a function that produces simulated observations $y$, taking *observed* inputs $x$ and latent parameters $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Latent parameters\n",
    "### Now the \"magic constants\" are passed in as parameters\n",
    "def how_tall_cm_latent(gender, *, mean_height=160, m_f_difference=6.5):\n",
    "    if gender==\"male\":\n",
    "        return mean_height + m_f_difference\n",
    "    if gender==\"female\":\n",
    "        return mean_height - m_f_difference  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_latent(\"male\", m_f_difference=10.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Uncertainty\n",
    "\n",
    ">    All theorems are true.  \n",
    ">    All models are wrong.  \n",
    ">    And all data are inaccurate.  \n",
    ">    What are we to do?  \n",
    ">    We must be sure to remain uncertain. \n",
    "\n",
    "-- *[Leonard A. Smith, Proc. International School of Physics ``Enrico Fermi\", (1997)](http://www2.maths.ox.ac.uk/~lenny/fermi96_main_abs.html)* \n",
    "\n",
    "<img src=\"imgs/uncertainty_forecast.png\">\n",
    "\n",
    "### What is uncertainty and where does it come from?\n",
    "Uncertainty exists in all systems that make contact with the real world. The physical world is not the domain of absolute logical truth, and the human social world is even less so. This is especially true when we project into the future (prediction, or forecasting), but even when reasoning about the present or the past, we must account for and be aware of the uncertainty involved.\n",
    "\n",
    "In interaction, we have, in the simplest case, two parties, or agents: \n",
    "\n",
    "* a brain, embedded in a human, embedded in a physical world\n",
    "* and software, embedded in computer hardware, embedded in the same physical world. \n",
    "\n",
    "Each of these \"agents\" has uncertainty about the other. Some of this uncertainty is due to the world that separates them (e.g. noise in the motor system). Some of it is because they do not (yet) have knowledge of each others' states.\n",
    "\n",
    "#### Epistemic, aleatoric and approximation\n",
    "\n",
    "We can separate out some *types* of uncertainty:\n",
    "\n",
    "* **Epistemic uncertainty** is uncertainty about what we know (hence epistemic) arising from the limitations of our knowledge (as encoded by a model).  If I've only ever met one person, my epistemic uncertainty about the height of people is likely to be large -- I don't *know* how tall people are.\n",
    "* **Aleatoric uncertainty** is that which arises from (presumed) randomness in the world. If I toss a coin, my uncertainty about which side lands face up is aleatoric. This type of uncertainty cannot be resolved by better modelling, more data, etc.; it is irreducible. Even if I have an excellent model of people's heights, any given person's height won't be precisely predicted by that model.\n",
    "* **Approximation uncertainty** arises from the limitations of computation to approximate inference. In general, Bayesian methods cannot be applied exactly, and so the results are subject to additional uncertainty.\n",
    "\n",
    "#### The wonder-goop\n",
    "Uncertainty is what makes a model *statistical*, and it can be used to model real randomness in phenomena. But we often have to build simple, tractable models that we know are *bad* models of the real world -- they simply can't represent the true complexity of an interactive system. We can just add uncertainty as \"goop\" to soak up the variation between the truth and the model; we *pretend* that there is randomness to mask the misalignment. If done correctly, our inferences are still correct, and *represent* the degree to which they have misfit reality.\n",
    "\n",
    "Uncertainty isn't *bad* -- it simply exists -- but ignoring it is demonstrably harmful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a function that is not a line\n",
    "def f(x):\n",
    "    return x + np.cos(x) * 0.2 - 0.0001 * x ** 4\n",
    "\n",
    "# a line does not fit\n",
    "# but a line + noise does\n",
    "# even though the \"noise\" is not random\n",
    "x = np.linspace(4, 16, 20)    \n",
    "y = f(x)\n",
    "p = np.polyfit(x, y, 1)\n",
    "y_prime = np.polyval(p, x)\n",
    "\n",
    "# plot the graph\n",
    "fig, ax = plt.subplots()\n",
    "err = 1\n",
    "for l in [0.25, 0.5, 1, 2]:\n",
    "    ax.fill_between(x, y_prime-l*err, y_prime+l*err, color='C0', alpha=0.2)\n",
    "\n",
    "ax.scatter(x, y, label='True', c='C1')\n",
    "ax.plot(x, y_prime, label='Approximate')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic results: sampling\n",
    "\n",
    "The simple models of height we wrote above are purely deterministic. In interaction, it's rare to have a model that can precisely predict an outcome, even if the parameters are known: models aren't exact representations of reality [epistemic], and reality isn't predictable anyway [aleatoric].\n",
    "\n",
    "A *statistical* data generating process would model the process with randomness, to reflect that we are drawing a (random) sample from a larger postulated population of possibilities. In practice, this just means we add random number generators to our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stochastic model\n",
    "### Implements aleatoric uncertainty\n",
    "def how_tall_cm_4(gender):\n",
    "    if gender==\"male\":\n",
    "        return np.random.normal(175, 10)\n",
    "    if gender==\"female\":\n",
    "        return np.random.normal(162, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_4(\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_tall_cm_4(\"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a a histogram\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist([how_tall_cm_4(\"male\") for i in range(100)], label=\"Male\")\n",
    "ax.hist([how_tall_cm_4(\"female\") for i in range(100)], label=\"Female\")\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 220)\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood: the backdoor key\n",
    "\n",
    "To do Bayesian modelling, we will need one more thing in our data generating processes: a measure of how \"likely\" an observation is to have been generated by the simulation. We can see this as a measure of compatibility of a possible observation with the particular parameters of a model.\n",
    "    \n",
    "> Note that we can sometimes work around this requirement  and use pure simulation models, using **approximate Bayesian computation (ABC)** -- but this tends to be quite inefficient. Still, the ABC approach, means we can use any model, without this likelihood function. \n",
    "\n",
    "This special feature will be the key to letting us *invert* our simulator, and work out how it is configured by feeding it possible data it might have generated.\n",
    "\n",
    "For now, we'll assume we just get a number telling us how good a fit an observation is given some parameters; the lower the number, the worse the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Likelihood: this is a function of data\n",
    "### There's no randomness here!\n",
    "def how_tall_cm_lik(gender, observed_height):    \n",
    "    if gender==\"male\":\n",
    "        return ss.norm(175, 8).logpdf(observed_height)\n",
    "    if gender==\"female\":\n",
    "        return ss.norm(162, 7).logpdf(observed_height)\n",
    "    \n",
    "print(\"male, 175cm tall\", how_tall_cm_lik(\"male\", 175))\n",
    "print(\"female, 175cm tall\", how_tall_cm_lik(\"female\", 175))\n",
    "print(\"male, 155cm tall\", how_tall_cm_lik(\"male\", 155))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"male 17.5cm tall\", how_tall_cm_lik(\"male\", 17.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a plot of likelihood \n",
    "fig, ax = plt.subplots()\n",
    "heights = np.linspace(0, 350, 350)\n",
    "ax.plot(heights, [how_tall_cm_lik(\"male\", h) for h in heights], label=\"Male\")\n",
    "ax.plot(heights, [how_tall_cm_lik(\"female\", h) for h in heights], label=\"Female\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"Log-likelihood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inversion\n",
    "\n",
    "### A mysterious entity\n",
    "\n",
    "We can imagine that the phenomena we are interested in (some interaction problem, say) is a mysterious entity who emits observable quantities (like the time taken to click on a menu item) but whose internal operation is inscrutable.\n",
    "\n",
    "<img src=\"imgs/entity.png\">\n",
    "\n",
    "We can see the **data generating process** (our model) as a tame mysterious entity, who generates samples when simulating and can also judge the quality of observations (likelihood) when fed them.  The mysterious entity is controlled by parameters (dials) which adjust the simulation and its opinion of the quality of observations. What we want is to know *which* mysterious entity parameters are compatible with the true (but unseen) mysterious entity.\n",
    "\n",
    "### Bayesian inversion\n",
    "\n",
    "This is a problem of **inversion**; working out what was happening in the unobserved realm by deducing plausible behaviours compatible with the observations. Working out what age someone is given how tall they are is an inverse problem. Working out how tall they are given their age is a forward problem. In Bayesian modelling we use the **forward** model (the data generating process) as the key step to build our inversion model. \n",
    "\n",
    "> Other approaches solve inversion directly; for example we might build a machine learning model that predicts ages given heights by fitting a deep network to lots of paired `(age, height)` examples. We could then, at inference time, feed it a height and it would return an age. Critically, it would only return *one* age -- the best predicted age (as directed by the objective function used to train the network). This is very much **not** what we will do in the Bayesian models we will see later!\n",
    "\n",
    "> * ML models: typically invert by optimising to find a single inverse function.\n",
    "> * Bayesian models: invert by forming a distribution over inverse functions that are plausible, given observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What is a Bayesian [II]?\n",
    "\n",
    "A Bayesian:\n",
    "\n",
    "* Builds generative models of the phenomena under consideration, that simulate plausible observations.\n",
    "* Represents, preserves and manipulates uncertainty about unknown parameters. Uncertainty is **first-class**.\n",
    "* Reasons about the unknown parameters that modulate the behaviour of those generative models.\n",
    "* Uses *likelihood* to invert forward models.\n",
    "\n",
    "\n",
    "# Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representations of uncertainty\n",
    "We need to formalise the representation of uncertainty in our models. There are many possible ways to do this, but arguably only one good way: **probability**. Bayesians represent all uncertainty via probability, and describe the relative plausibility of states via **probability distributions**.\n",
    "\n",
    "## What is probability?\n",
    "\n",
    "A fraught philosophical question! See the references for debates on this topic. We'll make some uncontroversial statements, then an *interpretation* of probability. \n",
    "\n",
    "**Probability, as we shall use it, is simply an extension of ordinary logic to uncertain situations.**\n",
    "\n",
    "\n",
    "### Basic facts\n",
    "\n",
    "* We'll talk about **random variables**, written like $X$, that represent values we don't know. We do know their **probability distribution**, however.\n",
    "\n",
    "* Probabilities are real numbers.\n",
    "\n",
    "* A probability distribution associates a set of distinct *outcomes* (values) with probabilities. $P(X=x)$ meaning the probability that variable $X$ takes on outcome $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outcome : probability\n",
    "coin_toss = {\"heads\": 0.5, \"tails\":0.5} \n",
    "\n",
    "robot_direction = {\"fwd\":0.6, \"left\":0.1, \"right\":0.0, \"back\":0.3}\n",
    "\n",
    "dice_throw = {1:1/6, 2:1/6, 3:1/6, 4:1/6, 5:1/6, 6:1/6}\n",
    "\n",
    "user_emotion = {\"happy\":0.1, \"sad\":0.2, \"excited\":0.05, \"angry\":0.1, \n",
    "                \"confused\":0.5, \"crazed\":0.05, \"jubilant\":0.05}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Probabilities are non-negative and cannot exceed 1: $0 \\leq P(A) \\leq 1$ \n",
    "* The probability of all possible outcomes in a distribution sums to 1 exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper(dist):\n",
    "    ps = dist.values()\n",
    "    assert all(0<=p<=1 for p in ps), \"Probability is not in [0,1]\"\n",
    "    assert sum(ps) == 1.0, \"Distribution does not sum to 1\"\n",
    "    return True\n",
    "\n",
    "proper(coin_toss) # fine\n",
    "proper(robot_direction) # fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proper({\"fwd\":0.6, \"left\":0.1, \"right\":0.0, \"back\":0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We deal with sets of possible outcomes; the set of all outcomes in our \"model\" is the *sample space*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_space(dist):\n",
    "    return list(dist.keys())\n",
    "\n",
    "sample_space(robot_direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An *event* is any set of outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_of(event, dist):\n",
    "    return sum(dist[outcome] for outcome in event)\n",
    "\n",
    "p_of({\"fwd\", \"back\"}, robot_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_of({\"happy\", \"sad\", \"crazed\"}, user_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If A and B are events $P(A \\lor B) = P(A) + P(B) - P(A\\land B)$ (sum rule; A and B are sets of outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rule(a, b, dist):\n",
    "    p_a = p_of(a, dist)\n",
    "    p_b = p_of(b, dist)\n",
    "    p_ab = p_of(a.intersection(b), dist)\n",
    "    return p_a + p_b - p_ab\n",
    "\n",
    "sum_rule({\"right\", \"back\"}, {\"back\", \"left\"}, robot_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_of({\"right\", \"back\", \"left\"}, robot_direction) # just the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of any set of events that cover all outcomes is therefore also 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If A has probability $P(A)=P(X \\in A)$, $P(Â¬A)=P(X \\notin A)=1-P(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of two *independent* events A and B is $P(A \\land B) = P(A)P(B)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_rule(a, b, dist_a, dist_b):\n",
    "    return p_of(a, dist_a) * p_of(b, dist_b)\n",
    "\n",
    "# what's the probability we go forward and we toss a coin that is heads?\n",
    "product_rule({\"fwd\"}, {\"heads\"}, robot_direction, coin_toss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of A *given we know that* an event B is true is written $P(A|B) = P(A \\land B)/P(B)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(a, b, dist):\n",
    "    a_and_b = p_of(a.intersection(b), dist)\n",
    "    return a_and_b / p_of(b, dist)\n",
    "\n",
    "# p(happy) given that I am happy, sad or confused\n",
    "condition({\"happy\"}, {\"happy\", \"sad\", \"confused\"}, user_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of P(A|B) is **not** (in general) P(B|A)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition({\"happy\", \"sad\", \"confused\"}, {\"happy\"}, user_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes' Rule (for the first time)\n",
    "\n",
    "* $P(A|B) = P(B|A)P(A) / P(B)$ (Bayes' Rule)\n",
    "* $P(B) = \\sum_B P(B|A)P(A)$ \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple probability distribution\n",
    "\n",
    "I grab a single coin from my pocket. We assume they are all Euro coins. That's our space of possibilities -- the sample space.\n",
    "\n",
    "\n",
    "* Regardless of what distribution of coins I have in my pocket, it cannot be less than impossible to pick a specific coin, nor more than certain.\n",
    "* Probability of 0 means impossible* (caveats apply) and probability of 1 means certain.\n",
    "* A probability distribution might map each coin (outcome) to a probability, a real number in [0,1]; for example:\n",
    "\n",
    "<img src=\"imgs/coin.png\">\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = {0.01: 0.02,\n",
    "         0.02 : 0.05,\n",
    "         0.05 : 0.1,\n",
    "         0.1 : 0.1,\n",
    "         0.2 : 0.2, \n",
    "         0.5 : 0.2,\n",
    "         1.0 : 0.3,\n",
    "         2.0 : 0.03}\n",
    "\n",
    "proper(coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of the coin being worth >50c is an *event*; perhaps $P(v>0.5)=P(v \\in {1.0, 2.0})=0.33$\n",
    "* A coin might be worth less than 10 cents $P(v<0.1) = P(v \\in \\{0.01, 0.02, 0.05\\})$ \n",
    "* or being gold-coloured $P(v \\in \\{0.1, 0.2, 0.5\\})$, or being 1 euro $P(v \\in \\{1.0\\})$. \n",
    "\n",
    "These are all events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_coins = sample_space(coins)\n",
    "gold = {0.1, 0.2, 0.5}\n",
    "\n",
    "print(\"P(v<0.1)\", p_of([coin for coin in possible_coins if coin<0.1], coins))\n",
    "print(\"P(v gold)\", p_of(gold, coins))\n",
    "print(\"P(v=1.0)\", p_of({1.0}, coins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since we must draw exactly one coin, the event that includes all coins must have probability 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_of(possible_coins, coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of a coin being less than 20c or more than *or* equal to 20c must also be 1.0, by the same logic (we cover every outcome exactly once). $P(v < 0.2 \\lor v\\geq 0.2) = P(v<0.2) + P(v \\geq 0.2) = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.2\n",
    "(p_of([coin for coin in possible_coins if coin<k], coins) + p_of([coin for coin in possible_coins if coin>=k], coins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability of a coin being less than 50c or being gold-coloured is $P(v < 0.5 \\lor v \\in \\{0.2, 0.5\\}) = P(v<0.5) + P(v \\in \\{0.2, 0.5\\}) - P(v<0.5 \\land v \\in \\{0.2, 0.5\\}) = P(v<0.5) + P(v \\in \\{0.2, 0.5\\}) - P(v=0.5)$ -- we compensate for \"double counting\" the overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gold_or_50 = (p_of(gold, coins) \n",
    "                + p_of([coin for coin in coins if coin<0.5], coins) \n",
    "                - p_of([coin for coin in coins if coin<0.5 and coin in gold], coins))\n",
    "\n",
    "print(p_gold_or_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_or_50 = set(gold) | set([coin for coin in coins if coin<0.5])\n",
    "print(p_of(gold_or_50, coins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The probability that I draw a coin that is gold coloured and it is a Spanish coin is $P(gold \\land Spanish) = P(gold)P(Spanish)$, assuming these are independent (e.g. I don't specially collect gold-coloured Spanish euro coins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coin_countries = {\"Spanish\":0.1, \"French\":0.1, \"German\":0.4, \"Finnish\":0.1, \n",
    "                 \"Danish\":0.0, \"Irish\":0.1, \"Italian\":0.1,  # Danes don't use Euros :)\n",
    "                 \"Czech\":0.05, \"Austrian\":0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_rule(gold, {\"Spanish\"}, coins, coin_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> * But the probability that I draw coin that is copper coloured and Finnish is **not** $P(copper)P(Finnish)$ (because 1c and 2c Finnish coins are very rare)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* The probability that I draw a gold coin given that the coin is less than a euro is $P(gold | v<1.0) = P(v \\in \\{0.1, 0.2, 0.5\\}) / P(v \\in \\{0.01, 0.02, 0.05, 0.1, 0.2, 0.5\\}) \\approx 0.746...$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_100 = {coin for coin in coins if coin<1.00}\n",
    "p_of(gold & less_100, coins) / p_of(less_100, coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **But note!** the probability that I draw a coin less than a euro given that it is gold is $P(v < 1.0 | gold) = P(v \\in \\{0.1, 0.2, 0.5\\}) / P(v \\in \\{0.1, 0.2, 0.5\\}) = 1.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_of(gold, coins) / p_of(less_100 & gold, coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Random variables and distributions\n",
    "\n",
    "We'll use the following definitions of terms:\n",
    "\n",
    "* A **random variable** $X$ is a variable whose value is not known, but whose possible values *are* known, and how likely those values are is also known. Probability theory allows us to manipulate random variables without having to assign them a specific value.\n",
    "* A **probability distribution** $P(X=x)$ associates a random variables outcomes to probabilities. It encodes the plausibility of a variable's outcomes.\n",
    "* A **probability mass function** $f_X(x)$ is a function that yields probabilities as a function of outcomes. This is just the dictionaries `{outcome: p}` we've already used.\n",
    "* If we have uncountable outcomes (like real numbers), we instead use a **probability density function** $f_X(x)$, which just guarantees the rules above hold for dense subsets of the outcomes, even if they can't hold for individual outcomes.\n",
    "    * Densities are not probabilities! They are non-negative, but can be greater than 1; the *integral* of a density over some domain *is* a probability. (e.g. $P(1\\leq \\text{age} \\leq 2) = \\int_1^2 f_X(\\text{age}) dx$ over the interval [1, 2] of $\\mathbb{R}$) \n",
    "\n",
    "A random variable could represent:\n",
    "\n",
    "* whether or not a user is paying attention (discrete: binary), over the set of outcomes $\\{\\text{attending}, \\text{ignoring}\\}$; \n",
    "* the page of a document a user is reading $\\{1,2,3,\\dots\\}$ (discrete); \n",
    "* the length of a user's arm (continuous), over the set of outcomes $\\mathbb{R}$; \n",
    "* the gaze angle of a user's pupil with respect to a screen (continuous, multi-dimensional), over the set of outcomes $\\mathbb{R}^2$. \n",
    "* a distribution over computer programs (discrete; infinite).\n",
    "\n",
    "Each would have a distribution, defined by a probability mass or density function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "A **probability distribution** defines how likely different states of a random variable are. \n",
    "\n",
    "We can see $X$ as the the *experiment* and $x$ as the *outcome*, with a function mapping every possible outcome to a probability. \n",
    "\n",
    "> Be careful: these are *notional* experiments, not real ones. They might involve things that are in the past, or have no randomness. They are subjective experiments from the perspective of an agent. \n",
    "\n",
    "$$\n",
    "P(A),\\  \\text{the probability of an event A}, \\text{equivalent to} P(X \\in A)\\\\\n",
    "P(X=x),\\  \\text{the probability of random variable X taking on value x}\\\\\n",
    "P(X),\\  \\text{shorthand for distribution of X }\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful!\n",
    "\n",
    "p_of({1, 2}, {1:0.5, 2:0.2, 3:0.1, 4:0.1}) # P(A), a number (from a set of outcomes)\n",
    "p_of({1}, {1:0.5, 2:0.2, 3:0.1, 4:0.1})    # P(X=x), a number from an outcome\n",
    "{1:0.5, 2:0.2, 3:0.1, 4:0.1}               # P(X), a distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Philosophy\n",
    "\n",
    "We will use the subjective Bayesian interpretation of probability. This has a simple statement but deep implications.\n",
    "\n",
    "* Probability is a *degree of belief*.\n",
    "* We express how strongly we believe something to be true with a probability. \n",
    "* We encode all beliefs as probability distributions. It's probabilities all the way down.\n",
    "* We manipulate all beliefs via the rules above. This naturally includes all of classical logic, where P=0 is False and P=1 is True.\n",
    "* We might expect that these probabilities would be *consistent* with observed relative frequencies of some random repeated process, but **that's not our definition of probability**. We do not invoke the mystical infinitely repeated identical experiments!\n",
    "* It's completely fine to make statements like:\n",
    "    * \"the probability the next dice throw will be a four\"\n",
    "    * \"the probability that it is raining right now\"\n",
    "    * \"the probability that 2^10^10^10-1 is prime\"\n",
    "    * \"the probability that the 2012 Olympics was in London\" (think carefully about what the probability might be!)\n",
    "    \n",
    "* Because this form of probability theory is merely a logic of uncertain beliefs, we must always reason from some starting point. Rather than **axioms**, as in classical logic, we instead begin from **prior distributions**, associating beliefs to probabilities at the start of a reasoning process.\n",
    "\n",
    "> We shall move from \"what proportion of times will I draw a 50c coin from my pocket?\" to \"what do you *believe* about my having a 50c coin?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random parameters\n",
    "* We will associate probability distributions with the *parameters* of our data generating processes.\n",
    "    * After all, we want to encode beliefs about what parameters could be reasonable.\n",
    "    \n",
    "* These distributions capture our *epistemic* uncertainty; they in turn may drive generation of random observations which have *aleatoric* uncertainty.\n",
    "* This means that we will have distributions over processes, who in turn (usually) have distributions over possible observations.\n",
    "* When we talk about Bayesian inference, we are talking about updating probability distributions over these parameters, given definite observations.\n",
    "\n",
    "> In the age/height example at the top of the notebook, we'd put a probability distribution on the age *and* a probability distribution on the generated height. We'd then try and do inference, given a set of real, observed heights, to narrow down the likely ages.\n",
    "\n",
    "<img src=\"imgs/random_parameters.drawio.png\">\n",
    "\n",
    "### Computer science\n",
    "\n",
    "* Probability is a **universal language** for expressing uncertain states.\n",
    "* Anything that \"speaks probability\" can be plugged into any other component that also does so.\n",
    "    * (at least if we can map sample spaces onto each other)\n",
    "* Probability is easy to encode in data structures for finite, discrete problems and the algorithms are simple\n",
    "    * A hash table/dictionary or plain array can do most of the work.\n",
    "* It is harder in continuous, multi-dimensional spaces or those with exotic topology.\n",
    "    * Consequently, we will virtually always have to **approximate** probabilities in these situations.\n",
    "    * And we will have to build and use approximation algorithms to do the hard work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability mass functions and probability density functions\n",
    "\n",
    "We won't worry about the distinction too much in this brief intro. The main points are:\n",
    "\n",
    "* A PDF is a function that maps outcomes to *densities*. These are not probabilities. They can be >1 (but must be positive).\n",
    "* We can ask the probability that an outcome \"lands\" in any dense subset of a PDF (e.g. a contiguous range). This *is* a probability.\n",
    "* It's often necessary to work with parametric functions for PDFs -- we end up manipulating the *parameters* computationally.\n",
    "    * For example, a normal density has two parameters, $\\mu$ and $\\sigma^2$. From this we can evaluate a PDF function.\n",
    "* It's often easier to think of the *cumulative distribution function*, the probability that an outcome lies below some threshold $x$.\n",
    "    * This *is* a probability, and runs from 0 to 1 across the real numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a PDF plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def how_tall_cm_pdf(gender, observed_height):    \n",
    "    if gender==\"male\":\n",
    "        return ss.norm(175, 10).pdf(observed_height)\n",
    "    if gender==\"female\":\n",
    "        return ss.norm(162, 7).pdf(observed_height)\n",
    "    \n",
    "heights = np.linspace(0, 350, 350)\n",
    "ax.plot(heights, [how_tall_cm_pdf(\"male\", h) for h in heights], label=\"Male\")\n",
    "ax.plot(heights, [how_tall_cm_pdf(\"female\", h) for h in heights], label=\"Female\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"$f_X$(height)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a CDF plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def how_tall_cm_cdf(gender, observed_height):    \n",
    "    if gender==\"male\":\n",
    "        return ss.norm(175, 10).cdf(observed_height)\n",
    "    if gender==\"female\":\n",
    "        return ss.norm(162, 7).cdf(observed_height)\n",
    "    \n",
    "heights = np.linspace(0, 350, 350)\n",
    "ax.plot(heights, [how_tall_cm_cdf(\"male\", h) for h in heights], label=\"Male\")\n",
    "ax.plot(heights, [how_tall_cm_cdf(\"female\", h) for h in heights], label=\"Female\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Height\")\n",
    "ax.set_ylabel(\"P(X<height)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We seek a logical process to perform inference: the deduction of the hidden from the seen. We seek to do so under uncertainty, where we do not deal in absolutes of truth and falsity.\n",
    "\n",
    "* Our primary tool is Bayes Rule. \n",
    "* The ability to do inference is derived from the ability to say: how likely is some unseen X given we saw Y?\n",
    "    * \"How likely is it that I am less than ten years old, given I am 120cm?\"\n",
    "        * I can see height; I can't see age.\n",
    "    * We can answer that as:\n",
    "        * It is the probability that we'd observe Y if X were true; multiplied by how likely we *already* believe X to be true; and normalised so that the probability for each possible X sums up to 1.\n",
    "        \n",
    "        \n",
    "$$P(H|D) = \\frac{P(D|H)P(H)}{P(D)} = \\frac{P(D|H)P(D)}{\\sum_H P(D|H)P(D)}$$\n",
    "\n",
    "$$P(H|D) \\propto P(D|H)P(D)$$ \n",
    "\n",
    "if all we care about is how *relatively* likely each possible $H$ is (not how *absolutely* likely it is)\n",
    "\n",
    "* These parts have names:\n",
    "    * `posterior = likelihood * prior / evidence`\n",
    "    * **posterior** $P(H|D)$ The probability of beliefs about $H$ after having observed $D$\n",
    "    * **likelihood** $P(D|H)$ How likely $D$ is to be observed under any possible hypothesised $H$\n",
    "    * **prior** $P(H)$ How currently likely $D$ is before observing $H$\n",
    "    * **evidence** $P(D)$ How likely $D$ is to be observed regardless of what hypothesis we make about $H$\n",
    "    \n",
    "> Note: we'll often use $\\theta$ instead of H to imply that the hypothesis is a vector of parameters called $\\theta$. We may also call $H$ $X$ and $D$ $Y$.\n",
    "\n",
    "* The likelihood of D, written $L(D)$ is how likely $D$ is to be observed under a particular model. Often written $L(D|\\theta)$ to mean \"the likelihood of X under some specific parameters \\theta\".\n",
    "    * Probabilities speak of the \"future\", of the relative propensity for unobserved outcomes to occur.\n",
    "    * Likelihoods speak of the \"past\", of observed states. They are just a function of observations/data, and they tell us how likely observed outcomes are under some assumption.\n",
    "    * The likelihood is $L(x) = f_X(x)$, just the mass/density evaluated for a specific outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and inverse probability\n",
    "\n",
    "* Questions of **forward probability** are likely to be familiar to you; they are the backbone of frequentist statistics, and they ask questions about the future outcomes given a probability distribution:\n",
    "    * \"What is the probability of drawing three 20c coins in a row\" -> $P(D|H)$ -> FORWARD\n",
    "    \n",
    "* Questions of **inverse probability** require Bayesian inference, and they ask questions about the probability of the causes of outcomes already observed:\n",
    "    * \"What is the probability I only have gold coins, if I draw three 20c coins in a row\" -> $P(H|D)$  -> INVERSE\n",
    "\n",
    "In general, we want to do the inverse probability calculations not for one specific question (as above), but instead for an *entire* probability distribution:\n",
    "\n",
    "* \"What is the distribution over coins, given I draw three 20c coins in a row\".\n",
    "\n",
    "Note the difference between frequentist and Bayesian interpretations here:\n",
    "\n",
    "* Frequentist statistics asks questions about infinite repeated trials, where we assume random outcomes but fixed (unknown) parameters.\n",
    "* Bayesian statistics asks questions about random parameters, given fixed observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Bayesian? [III]\n",
    "\n",
    "A **Bayesian**:\n",
    "\n",
    "* Represents belief exclusively using probability distributions and conducts all computation about beliefs via the logic of probability.\n",
    "* Reasons from hypotheses about the world to the evidence that those hypotheses would generate (via a data generating process).\n",
    "* Updates belief using Bayes' Rule, combining a prior belief with observed evidence to deduce new beliefs.\n",
    "* Infers conditional distributions -- posterior distributions -- over unseen parameters of the DGP.\n",
    "\n",
    "Given a parameterised simulator that approximates the problem we are interested in, and some idea about what values these parameters could take on (expressed as a prior probability distribution) we can then use evidence to make a Bayesian update to concentrate a belief distribution on more likely parameter configurations --- a posterior probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "Let's quickly review the operations on probability distributions we need in order to do Bayesian inference. We'll show each in code, with a simple example.\n",
    "\n",
    "### A menu\n",
    "Let's model a menu in an application. We might assume that there is some probability that different menu items will be selected by a user (we might have estimated this in various ways, but for now we'll just assume it is known).\n",
    "\n",
    "<img src=\"imgs/menu.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = {\"new\": 0.02,\n",
    "         \"settings\" : 0.05,\n",
    "         \"revert\" : 0.05,\n",
    "         \"save as\" : 0.15,\n",
    "         \"new\" : 0.2, \n",
    "         \"open\" : 0.22,\n",
    "          \"save\":0.3,\n",
    "         \"rename\" : 0.03}\n",
    "\n",
    "proper(menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood\n",
    "\n",
    "Likelihood tells us for a fixed set of parameters, how likely an observation is. We need to define likelihood functions to define a Bayesian data generating process. We usually use the *log*-likelihood to avoid numerical issues; in particular if we take the product of many independent likelihoods, we can instead write the sum of the log-likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(outcome, pmf):\n",
    "    return pmf[outcome]\n",
    "\n",
    "def loglik(outcomes, pmf):\n",
    "    # log-lik of a collection of independent outcomes\n",
    "    return sum(np.log(pmf[outcome]) for outcome in outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood(\"open\", menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loglik([\"open\", \"save\", \"open\"], menu))\n",
    "print(loglik([\"new\", \"revert\", \"settings\"], menu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "Sampling is the process of drawing definite realisations from a distribution. For discrete values, it is easy; for continuous values it may not be straightforward. \n",
    "\n",
    "This is the synthesis or simulation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(pmf, n=1):\n",
    "    return list(np.random.choice(list(pmf.keys()), p=list(pmf.values()), size=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(menu, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical distribution\n",
    "We can estimate probability distributions from data. In the case of discrete sample spaces, we can estimate a PMF simply by counting the number of each outcomes observed, and normalising by the total number of observations overall. **This lets us learn PMFs from historical data by simple frequency estimation.**\n",
    "\n",
    "This is the opposite of sampling -- estimating the PMF from samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def from_empirical(observations):\n",
    "    c = Counter(observations)\n",
    "    total = sum(c.values())\n",
    "    return {outcome: count / total for outcome, count in c.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trace = [\"open\", \"save\", \"open\", \"save as\", \"open\", \"open\", \"new\"]\n",
    "from_empirical(user_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling <-> empirical distribution\n",
    "If we estimate the empirical distribution from samples, we'll eventually recover the true PMF (if we had infinite samples, anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(from_empirical(sample(menu, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(from_empirical(sample(menu, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(from_empirical(sample(menu, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(from_empirical(sample(menu, 100_000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation\n",
    "The expectation is a key operation. It gives us the average \"value\" of a function applied to the outcomes of a distribution. \n",
    "It's just the sum of the outcome's values, weighted by their probabilities. It is written:\n",
    "\n",
    "$$E[g(X)] = \\sum_{x\\in X}g(x) p(X=x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectation(pmf, g=lambda x: x):\n",
    "    return sum(g(outcome) * p for outcome, p in pmf.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danger = {\"new\":5, \"open\":5, \"save\":1, \"save as\":0, \"revert\":10, \"settings\":0, \"rename\":1}\n",
    "\n",
    "expectation(menu, lambda item:danger[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or the expected value of a random coin\n",
    "expectation(coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Approximate expectation\n",
    "\n",
    "Sometimes the sample space is too large to exhaustively sum (or integrate). A very important identity says that we can approximate any expectation by drawing $N$ samples, applying the function to each, and computing the average result. That is: we simulate, then compute the average value of the simulations. This is the basis of Monte Carlo methods.\n",
    "\n",
    "$$ E[g(X)] \\approx \\frac{1}{N} \\sum_{i=1}^{N} g(x) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_approx(sample_fn, n, g=lambda x: x):\n",
    "    return sum(g(sample_fn()) for i in range(n))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_approx(lambda: sample(menu)[0], 10, lambda item:danger[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expect_approx(lambda: sample(coins)[0], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Entropy\n",
    "\n",
    "One  useful function before we get to Bayes' rule is the **entropy** of a distribution: $$H(X) = \\sum P(X=x) \\log_2 P(X=x),$$ the expected log probability of the outcomes. It measures the uncertainty or diversity of a probability distribution. A larger value indicates more uncertainty; this is how we quantify the **information** flowing over a communication channel -- in terms of the drop in uncertainty that the information brings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(pmf):\n",
    "    return -sum(0 if p==0 else p * np.log2(p) for p in pmf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_menu = {\"new\": 1/8,\n",
    "            \"settings\" : 1/8,\n",
    "             \"revert\" : 1/8,             \n",
    "            \"save as\" : 1/8,\n",
    "             \"new\" : 1/8, \n",
    "            \"open\" : 1/8,             \n",
    "             \"save\":1/8,\n",
    "              \"rename\" : 1/8,\n",
    "            \"close\":1/8}\n",
    "# 3 bits = equally likely to be any of eight choices\n",
    "entropy(flat_menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certain_menu = {\"new\": 0.0,\n",
    "            \"settings\" : 1.0,\n",
    "             \"revert\" : 0.0,             \n",
    "            \"save as\" : 0.0,\n",
    "             \"new\" : 0.0, \n",
    "            \"open\" : 0.0,             \n",
    "             \"save\":0.0,\n",
    "              \"rename\" : 0.0,\n",
    "            \"close\":0.0}\n",
    "# 0 bits; the outcome is known in advance\n",
    "entropy(certain_menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divergence\n",
    "The **divergence** or *relative entropy* of two distributions is essentially the change in entropy to move from one to the other. It tells us how much information is \"required\" to move between distributions. The divergence *from Q to P* is:\n",
    "\n",
    "$$D_{KL}(P||Q) = \\sum_{x\\in X}P(X=x) \\log_2\\left(\\frac{P(X=x)}{Q(X=x}\\right)$$\n",
    "\n",
    "It is **not** symmetric: $D_{KL}(P||Q) \\neq D_{KL}(Q||P)$ in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divergence(p, q):\n",
    "    return sum([p[x] * np.log2(p[x]/q[x]) for x in p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_menu = {\"new\": 1/8,\n",
    "         \"settings\" : 1/8,\n",
    "         \"revert\" : 1/8,             \n",
    "         \"save as\" : 1/8,\n",
    "         \"new\" : 1/8, \n",
    "         \"open\" : 1/8,             \n",
    "          \"save\":1/8,\n",
    "         \"rename\" : 1/8}\n",
    "\n",
    "divergence(flat_menu, menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergence(menu, flat_menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Rule\n",
    "Bayes' rule is the key algorithm for inference. For small discrete problems, we can compute it *exactly*. The operation is trivial: multiply a prior distribution with a likelihood, then normalise it so that it still sums to 1.\n",
    "\n",
    "$$P(H|D) = \\frac{P(D|H)P(H)}{P(D)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes(prior, likelihood):\n",
    "    assert (prior.keys()) == (likelihood.keys())\n",
    "    unnorm = {k: prior[k] * likelihood[k] for k in prior}\n",
    "    s = sum(unnorm.values())\n",
    "    return {k:unnorm[k] / s for k in unnorm}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we know the user's finger is somewhere near \"Save as...\" but not exactly where it is:\n",
    "\n",
    "<img src=\"imgs/menu_hover.png\" width=\"40%\">\n",
    "\n",
    "We might ascribe a likelihood to each menu item based on how likely the users finger was to be in that location given they wanted to select that item. We can combine this evidence with our prior model of menu items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_lik = {\"new\": 0.0005,\n",
    "             \"open\" : 0.0195,\n",
    "             \"save\":0.15,\n",
    "             \"save as\" : 0.4,\n",
    "             \"revert\" : 0.4,                                        \n",
    "             \"rename\" : 0.02,\n",
    "            \"settings\" : 0.0005,}\n",
    "bayes(menu, hover_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much information did we gain about the targets?\n",
    "divergence(bayes(menu, hover_lik), menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hover_lik_tight = {\"new\": 0.0001,\n",
    "                 \"open\" : 0.0001,\n",
    "                 \"save\":0.0001,\n",
    "                 \"save as\" : 0.4996,\n",
    "                 \"revert\" : 0.4996,                                        \n",
    "                 \"rename\" : 0.0001,\n",
    "                \"settings\" : 0.0001,}\n",
    "bayes(menu, hover_lik_tight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much information did we gain in this case?\n",
    "divergence(bayes(menu, hover_lik_tight), menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bayes_table(pmf, likelihood):\n",
    "    unnorm = {k: pmf[k] * likelihood[k] for k in pmf}\n",
    "    s = sum(unnorm.values())  \n",
    "    posterior =  {k:unnorm[k] / s for k in unnorm}\n",
    "    df = pd.DataFrame(zip(pmf.keys(), pmf.values(), likelihood.values(), unnorm.values(), posterior.values()), columns = [\"Item\", \"Prior\", \"Likelihood\", \"Unnormalised\", \"Posterior\"])\n",
    "    return df \n",
    "\n",
    "bayes_table(menu, hover_lik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint\n",
    "\n",
    "\n",
    "We often have situations where we have distributions over several variables, written $P(X,Y)$. The **joint** distribution is just the probability distribution of every pair (triple, etc.) of variables $P(X=x, Y=y)$.\n",
    "\n",
    "If $X$ and $Y$ are independent, then $P(X=x, Y=y) = P(X=x)P(Y=y)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint(pmf, other):\n",
    "    \"\"\"Only valid for two *independent* PMFs!\"\"\"\n",
    "    return (\n",
    "        {\n",
    "            (a, b): p_a * p_b\n",
    "            for (a, p_a), (b, p_b) in itertools.product(\n",
    "                pmf.items(), other.items()\n",
    "            )\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps users can be *editing* or *creating* in this software. These might be independent of the menu choices they would make, so the joint would be a simple product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_task = {\"editing\":0.5, \"creating\":0.5}\n",
    "joint_d = joint(menu, user_task)\n",
    "joint_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full joint distribution\n",
    "But a more realistic model might include joint dependencies. For example, an editing user might be much more likely to be hitting \"save\" than \"new\".\n",
    "\n",
    "We'd need to specify this explicitly, giving probabilities to each pair of outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_t = {  ('new', 'editing'): 0.001,\n",
    "             ('new', 'creating'): 0.168,\n",
    "             ('settings', 'editing'): 0.028,\n",
    "             ('settings', 'creating'): 0.028,\n",
    "             ('revert', 'editing'): 0.028,\n",
    "             ('revert', 'creating'): 0.006,\n",
    "             ('save as', 'editing'): 0.107,\n",
    "             ('save as', 'creating'): 0.028,\n",
    "             ('open', 'editing'): 0.236,\n",
    "             ('open', 'creating'): 0.011,\n",
    "             ('save', 'editing'): 0.224,\n",
    "             ('save', 'creating'): 0.112,\n",
    "             ('rename', 'editing'): 0.017,\n",
    "             ('rename', 'creating'): 0.006}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal\n",
    "If we have a distribution over several variables we can remove one or more by *marginalising it out*. This just means summing over the possible values for that variable. Marginisation reduces the \"dimension\" of a joint probability distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Marginal\n",
    "def apply_mask(outcome, mask):\n",
    "    return tuple(\n",
    "            [component for masked, component in zip(mask, outcome) if not masked]\n",
    "        )\n",
    "        \n",
    "def marginal(pmf, mask):    \n",
    "    acc = {}\n",
    "    for outcome, p in pmf.items():\n",
    "        removed = apply_mask(outcome, mask)\n",
    "        acc[removed] = acc.get(removed, 0) + p\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the second variable\n",
    "marginal(joint_d, (True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal(joint_d, (False, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the probabilities here actually imply different\n",
    "# probabilities of editing versus creating\n",
    "marginal(joint_t, (True, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple variables\n",
    "We can have any number of variables in a joint distribution, but it gets messy doing this by hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint3(p1, p2, p3):\n",
    "    \"\"\"Only valid for two *independent* PMFs!\"\"\"\n",
    "    return (\n",
    "        {\n",
    "            (a, b, c): p_a * p_b * p_c\n",
    "            for (a, p_a), (b, p_b), (c, p_c) in itertools.product(\n",
    "                p1.items(), p2.items(), p3.items()\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "joint3(menu, menu, menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional\n",
    "The conditional distribution $P(X|Y=y)$ is a distribution over $X$ (only) derived from a joint distribution $P(X,Y)$. We sometimes talk about $P(X|Y)$, which is a *set* of distributions for each possible Y but not a distribution itself (since it each value of Y yields a distribution that sums to 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditional\n",
    "def condition(pmf, condition):\n",
    "    acc = {}\n",
    "    for outcome, p in pmf.items():\n",
    "        cond_outcome = tuple(\n",
    "            comp if cond is None else cond for cond, comp in zip(condition, outcome)\n",
    "        )\n",
    "        if cond_outcome == outcome:\n",
    "            acc[cond_outcome] = acc.get(cond_outcome, 0) + pmf[outcome]\n",
    "    total = sum(acc.values())\n",
    "    return {apply_mask(outcome, condition): p / total for outcome, p in acc.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how likely am I to be hitting menu items, given I am editing?\n",
    "condition(joint_t, (None, \"editing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how likely am I to be hitting menu items, given I am creating?\n",
    "condition(joint_t, (None, \"creating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how likely am I to be editing or creating, given I hit open?\n",
    "condition(joint_t, (\"open\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conditional \"distribution\" P(X|Y)\n",
    "\n",
    "def none_product(prods, p=()):\n",
    "    if len(prods) == 0:\n",
    "        return p\n",
    "    first = prods[0]\n",
    "    if first is None:\n",
    "        return none_product(prods[1:], p + (None,))\n",
    "    else:\n",
    "        return [none_product(prods[1:], p + (elt,)) for elt in first]\n",
    "\n",
    "def conditions(pmf, conditions):      \n",
    "    def invert_mask(seq):\n",
    "        return [True if not s else False for s in seq]   \n",
    "    return {apply_mask(c,invert_mask(c)):condition(pmf, c) for c in none_product(conditions)}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each possible menu item, what is the distribution over creating/editing?\n",
    "\n",
    "pprint(conditions(joint_t, (menu.keys(), None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(conditions(joint_t, (None, [\"creating\", \"editing\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/joint_marginal.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "Let's look a simple example using these ideas: capturing and reporting user ratings for a product, in this case: food.\n",
    "\n",
    "## Assumptions\n",
    "We have a UI that shows how many people liked or disliked a food. Individual users provide ratings by clicking either ð or ð. \n",
    "\n",
    "We assume a population of users, and we want to know how \"good\" that population (as a single entity) thinks that food is; the \"hive mind\". \n",
    "\n",
    "### Data generating process\n",
    "* Step 1: describe the data generating process.\n",
    "\n",
    "We'll assume this simple model: the hive mind has a value $q$ between 0 and 1 that it ascribes to every food. Individual users, as drones of the hive mind, when exposed to food, randomly produce likes or dislikes *in proportion* to this value. \n",
    "\n",
    "### Observations\n",
    "A variable length sequence of ð or ð.\n",
    "\n",
    "## Code\n",
    "* Step 2: write down the simulator that generates samples, and a likelihood function that tells us how likely they are.\n",
    "\n",
    "We can now define a simulator in code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q -> epistemic uncertainty\n",
    "# we assume that n is independent \n",
    "# (but we don't have to)\n",
    "def product_sample(q, n):\n",
    "    like_pmf = {\"ð\":q,\"ð\":1-q}\n",
    "    return sample(like_pmf, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sample(0.25, 10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a likelihood function. In this case, it's easy: we have probability `q` of seeing a \"ð\" and a probability of `1-q` of seeing a ð. We can also return the sum of log-likelihoods for a string (sum of logs = product of values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lik(q, o):\n",
    "    like_pmf = {\"ð\":q,\"ð\":1-q}\n",
    "    return likelihood(o, like_pmf)\n",
    "    \n",
    "# return the log-likelihood of a string \n",
    "# under some specific setting of q    \n",
    "def product_llik(q, obs):    \n",
    "    like_pmf = {\"ð\":q,\"ð\":1-q}\n",
    "    return loglik(obs, like_pmf)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "* Step 3: collect, process and clean data \n",
    "\n",
    "We can now load some existing data with like/dislike counts that \"users\" have provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.read_csv(\"foods.txt\")\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a simple ranked list\n",
    "def rank_foods(foods):\n",
    "    foods[\"ratio\"] = foods[\"like\"] / (foods[\"like\"]+foods[\"dislike\"])\n",
    "    for ix,row in foods.sort_values(\"ratio\",ascending=False).iterrows():\n",
    "        food, ratio = row[\"food\"], row[\"ratio\"]\n",
    "        if ratio>0.5:\n",
    "            icon = \"ð\"\n",
    "        else:\n",
    "            icon = \"ð\"\n",
    "        print(f\"{icon} {food:20s} {ratio*100:.0f}% of users liked this!\")\n",
    "        \n",
    "rank_foods(foods)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian estimation\n",
    "\n",
    "* Step 4: perform inference\n",
    "\n",
    "What is inference in this case? We want to perform deduction -- invert the simulator so that we can work out `q` (the likability of the food) by observing sequences of characters. \n",
    "\n",
    "**We are Bayesian.** Therefore, we don't want a value for `q`, we want a *distribution* for `q`. \n",
    "\n",
    "> Distributions, not points!\n",
    "\n",
    "This implies:\n",
    "* We need to have a way of representing a distribution over `q` -- what data structure will we choose? (and what algorithm will that require?)\n",
    "* We need to start somewhere -- what prior for `q` will we believe *before we observe any food likes data*?\n",
    "\n",
    "### Grid model\n",
    "We'll use the simple grid model as our data structure, and evenly divide the interval [0, 1] into N discrete bins. I'll choose to set N=20 (but this is a fairly arbitrary choice).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import show_grid, show_products_mean, show_products_box, show_products_violin, show_products_table, show_products_swarm, show_products_strip\n",
    "\n",
    "possible_q = np.linspace(0, 1, 20)\n",
    "# make the initial distribution completely uniform\n",
    "p = np.ones_like(possible_q) / len(possible_q)\n",
    "q_pmf = {q:p for q, p in zip(possible_q, p)}\n",
    "\n",
    "            \n",
    "show_grid(q_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = {q:lik(q, 'ð') for q in q_pmf}\n",
    "next_pmf = bayes(q_pmf, update)\n",
    "show_grid(next_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = {q:lik(q, 'ð') for q in q_pmf}\n",
    "next_pmf = bayes(next_pmf, update)\n",
    "show_grid(next_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = {q:lik(q, 'ð') for q in q_pmf}\n",
    "next_pmf = bayes(next_pmf, update)\n",
    "show_grid(next_pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = {q:np.exp(product_llik(q, 'ðððððððððððð')) for q in q_pmf}\n",
    "next_pmf = bayes(q_pmf, update)\n",
    "show_grid(next_pmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic filtering and sequential (\"recursive\") updates\n",
    "\n",
    "The names *prior* and *posterior* can refer to distinct parts of a modelling process (e.g. I elicit a prior from an expert, then run an experiment to observe data that I use to compute a posterior). But the naming of prior and posterior is *purely relative*! \n",
    "\n",
    "It's completely fine for a prior for one step of an inference process to become the posterior for another step. Everything is just probability distributions, which are a universal language -- everything plugs together (over the same sample space, anyway).\n",
    "\n",
    "<img src=\"imgs/recursive.png\" width=\"50%\">\n",
    "\n",
    "We saw this above; we just fed in our observations of like or dislike one at a time, and got a new distribution at each step. We *can* feed them all at once, and the result is exactly the same (modulo numerical differences). In cases where data is streaming in over time, it is particularly useful that these recursive updates are easy. This is sometimes called *recursive* updates, or more commonly a *probabilistic filter*. Algorithms like the Kalman filter and particle filters are just ways of implementing this update for continuous (vector) spaces; *exact* in the case of Kalman filters, MCMC in the case of particle filters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = 'ððððððððððð'\n",
    "like_pmf = q_pmf.copy()\n",
    "for like in updates:\n",
    "    update = {q:lik(q, like) for q in q_pmf}\n",
    "    # recursive uodate\n",
    "    like_pmf = bayes(like_pmf, update)\n",
    "    show_grid(like_pmf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = {q:np.exp(product_llik(q, updates)) for q in q_pmf}\n",
    "single_pmf = bayes(q_pmf, update)\n",
    "show_grid(single_pmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing for our dataset\n",
    "We can just feed in our food like data to this model, computing one distribution for each food in the dataset. Since we have counts, rather than a big string, I'll write a slightly more efficient version of the likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_llik(q, like, dislike): \n",
    "    # return the likelihood for a count of likes and dislikes\n",
    "    return ss.binom.logpmf(like, like+dislike, q)\n",
    "\n",
    "# again, flat prior\n",
    "prior = {q:p for q, p in zip(possible_q, p)}\n",
    "\n",
    "# update each distribution\n",
    "food_pmfs = {}\n",
    "for ix, row in foods.iterrows():    \n",
    "    food_lik = {q:np.exp(count_llik(q, row[\"like\"], row[\"dislike\"])) for q in prior}\n",
    "    # prior -> posterior\n",
    "    updated_pmf = bayes(prior, food_lik)\n",
    "    food_pmfs[row[\"food\"]] = updated_pmf    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(food_pmfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting results\n",
    "We can report our results in various ways. For each product, we have a PMF. We could show this as Box plots, violin plots, gradient strips. What we should *not* do is just show the mean (or max or min)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_products_table(food_pmfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_products_mean(food_pmfs)\n",
    "show_products_box(food_pmfs)\n",
    "show_products_violin(food_pmfs)\n",
    "show_products_swarm(food_pmfs)\n",
    "show_products_strip(food_pmfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation\n",
    "If we wanted to rank the choices, we need a single numerical measure. We can obtain one via expectation. Because we preserved the whole distribution, we can select different \"lenses\" on the distribution by selecting different functions to apply to the outcomes, not just the mean.\n",
    "\n",
    "### The picky dinner guests\n",
    "Imagine we have different kinds of dinner party guests:\n",
    "* standard\n",
    "* cautious\n",
    "* relaxed\n",
    "* rigidly picky\n",
    "* controversial\n",
    "* weird food lover\n",
    "\n",
    "How would we rank foods to prepare under those assumptions? We'd value different $q$ values differently in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_products(pmfs, fn):    \n",
    "    expected = [(name, expectation(pmf, fn)) for name, pmf in pmfs.items()]\n",
    "    return sorted(expected, key=lambda x:-x[1])\n",
    "\n",
    "def show_ranks(pmfs, fn, eater_name=''):\n",
    "    fig, ax = plt.subplots(ncols=2)\n",
    "    xs = np.linspace(0,1, 100)\n",
    "    ax[0].plot(xs, [fn(x) for x in xs])\n",
    "    ranks = rank_products(pmfs, fn)\n",
    "    y = 0.9\n",
    "    ax[0].axis(\"off\")\n",
    "    for i, (name, score) in enumerate(ranks):\n",
    "        ax[1].text(0, y, f\"{i+1:4d} {name:20s} {score:3.2f}\", family=\"monospace\")\n",
    "        y -= 0.08\n",
    "    ax[1].set_ylim(0, 1)\n",
    "    ax[1].axis(\"off\")\n",
    "    fig.suptitle(eater_name)\n",
    "    \n",
    "        \n",
    "# mean rank        \n",
    "show_ranks(food_pmfs, lambda x:x, 'normal')\n",
    "# pessimistic\n",
    "show_ranks(food_pmfs, lambda x:x**3, 'cautious')\n",
    "# optimistic\n",
    "show_ranks(food_pmfs, lambda x:x**0.5, 'relaxed')\n",
    "# only if we're sure it's 90% good\n",
    "show_ranks(food_pmfs, lambda x:0 if x<0.90 else x, 'picky')\n",
    "# only controversial\n",
    "show_ranks(food_pmfs, lambda x:1-(x-0.5)**2, 'controversial')\n",
    "# backwards\n",
    "show_ranks(food_pmfs, lambda x:1-x**2, 'weird')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "The **entropy** of the posterior distribution tells us the uncertainty or \"how much is left to learn\". We can plot this as a way of identifying foods we should perhaps gather more data about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "def entropy(pmf):\n",
    "    return -sum(0 if p==0 else p * np.log2(p) for p in pmf.values())\n",
    "\n",
    "entropies = np.array([entropy(pmf) for pmf in food_pmfs.values()])\n",
    "entropy_order = np.argsort(entropies)\n",
    "ax.bar(np.arange(len(food_pmfs)), entropies[entropy_order] , tick_label=np.array(list(food_pmfs.keys()))[entropy_order])\n",
    "rotate_labels()\n",
    "ax.set_ylabel(\"Entropy (bits)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative priors\n",
    "One of the advantages of a Bayesian approach is that we can introduce *informative* priors.\n",
    "Can we incorporate prior information here? Yes, we can -- we might know that people generally like fruits. We can assign a more\n",
    "optimistic prior (more likely to have a high `q`) to the fruit items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat prior\n",
    "prior = {q:p for q, p in zip(possible_q, p)}\n",
    "\n",
    "# fruit has some prior likelihood of being good\n",
    "fruit_prior = bayes(prior, {q:np.exp(product_llik(q, 'ðððð')) for q in prior})\n",
    "\n",
    "show_grid(fruit_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update each distribution\n",
    "food_pmfs = {}\n",
    "for ix, row in foods.iterrows():\n",
    "    \n",
    "    food_lik = {q:np.exp(count_llik(q, row[\"like\"], row[\"dislike\"])) for q in prior}\n",
    "    # select the prior based on the fruit column\n",
    "    if not row[\"fruit\"]:\n",
    "        updated_pmf = bayes(prior, food_lik)\n",
    "    else:\n",
    "        updated_pmf = bayes(fruit_prior, food_lik)\n",
    "    food_pmfs[row[\"food\"]] = updated_pmf\n",
    "        \n",
    "\n",
    "show_products_strip(food_pmfs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor fusion!!!\n",
    "\n",
    "One of the major advantages of the Bayesian approach is that we model forwards. This makes it trivial to perform **sensor fusion**, the combination of evidence from multiple sources (e.g. from an IMU and a GPS in a vehicle tracking system). We just include the extra channel of information into our Bayesian update. \n",
    "\n",
    "\n",
    "Imagine we believed the \"quality\" of a product depended not only on the like/disklike distribution, but also on the number of exclamation marks in the product title. How could we introduce this information? Simple: write down a likelihood, telling us how likely $n$ question marks are given a $q$ and include it as the prior. It's just the same as how we incorporated the `fruit` indicator earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a generative model!\n",
    "def exclamation_sample(title, q):\n",
    "    return title + ss.poisson(q*4).rvs() * '!'\n",
    "\n",
    "def exclamation_lik(title, q):\n",
    "    return ss.poisson(q*4).pmf(title.count(\"!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood of observing this number of exclamation marks\n",
    "name = \"apples!\"\n",
    "exc_prior = {q:exclamation_lik(name, q) for q in q_pmf}\n",
    "exc_pmf = bayes(q_pmf, exc_prior)\n",
    "show_grid(exc_pmf)\n",
    "\n",
    "# and then introduce some like/dislike data\n",
    "like_lik = {q:np.exp(product_llik(q, \"ððððððð\")) for q in q_pmf}\n",
    "like_post = bayes(exc_pmf, like_lik)\n",
    "\n",
    "show_grid(like_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a generative model. So if we know how good something is, we can predict how many exclamation marks it ought to have in its listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exclamation_sample(\"apples\", 0.9))\n",
    "print(exclamation_sample(\"olives\", 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why fusion is easy in a Bayesian world\n",
    "Why did this work so easily? Because our model described what observations we would see under a given hypothesis, and *not* what hypothesis we would see under a given observation. This difference is critical: fusion is trivial with a forward model + Bayesian inference, but challenging to do with a direct inverse model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shadow worlds: latent and predictive\n",
    "\n",
    "![Shadow world](imgs/shadow_world.png)\n",
    "\n",
    "### (Prior, posterior) x (parameter, predictive)\n",
    "\n",
    "It's important to keep the various elements of a Bayesian model distinct.\n",
    "\n",
    "#### Over parameters (inference)\n",
    "* **Prior** a distribution over unknown parameters before some observations\n",
    "* **Posterior** a distribution over unknown parameters after observations\n",
    "\n",
    "#### Over observations (simulation)\n",
    "* **Prior predictive** a distribution over observations *that our model would generate* under the priors.\n",
    "* **Posterior predictive** a distribution over observations *that our model would generate* under the posterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "Let's show an example, for the posterior over licorice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lic_pmf = food_pmfs[\"licorice\"]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2)\n",
    "show_grid(prior, axs[0,0]) \n",
    "show_grid(lic_pmf, axs[1,0]) \n",
    "axs[0,0].set_title(\"Prior\")\n",
    "axs[1,0].set_title(\"Posterior\")\n",
    "\n",
    "prior_predictive = {'ð':expectation(prior), 'ð':1-expectation(prior)}\n",
    "show_grid(prior_predictive, axs[0,1])\n",
    "axs[0,1].set_title(\"Prior predictive\")\n",
    "axs[0,1].set_xticks([0.25, 0.75])\n",
    "axs[0,1].set_xticklabels(\"+-\")\n",
    "\n",
    "posterior_predictive = {'ð':expectation(lic_pmf), 'ð':1-expectation(lic_pmf)}\n",
    "show_grid(posterior_predictive, axs[1,1])\n",
    "axs[1,1].set_title(\"Posterior predictive\")\n",
    "axs[1,1].set_xticks([0.25, 0.75])\n",
    "axs[1,1].set_xticklabels(\"+-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(lic_pmf, 10) # posterior samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample(posterior_predictive, 10) # posterior predictive samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Bayesian modelling and inference process\n",
    "<img src=\"imgs/bayesian_flow.drawio.png\">\n",
    "\n",
    "### The process of eliciting, encoding and validating\n",
    "What does it look like to *do* Bayesian modelling? We need to do several things:\n",
    "\n",
    "* Elicit models (data generating processes) that we believe are good fits to the phenomena we expect;\n",
    "* Encode our beliefs about plausible configurations of those models mathematically, as prior distributions on parameters.\n",
    "* Infer posterior distributions over those parameters using an inference algorithm.\n",
    "* Validate that our modelling assumptions held true.\n",
    "* Report the results\n",
    "\n",
    "#### Elicit and encode\n",
    "\n",
    "* We need to write down the **data generating process**. \n",
    "    * This usually means we have a model that can both *sample* (simulate) \n",
    "    * and can be fed observations to return likelihoods. \n",
    "    * This model may have arbitrary internal structure, and might often have a hierarchical arrangement. \n",
    "* The **parameters** need to be identified, and ideally scaled/chosen such that they are *interpretable*.\n",
    "* We need to set **priors** for the parameters. This would typically be guided by existing data, expert opinions or other sources\n",
    "    * People often fret about setting priors, but the point is that it rarely matters greatly -- just encode what you know! If that turns out to be not very much, the model will still work just fine.\n",
    "    \n",
    "#### Infer\n",
    "* We then need to apply an inference algorithm to update the probability distribution over parameters.\n",
    "* This typically involves an approximate iterative algorithm\n",
    "* The output is a representation of the **posterior** distribution over model parameters\n",
    "* This will often be *samples* from the posterior distribution (if using MCMC, as described below)\n",
    "\n",
    "#### Validate\n",
    "* We must validate that our modelling choices are reasonable and that our DGP behaves as it ought. For example, we might check:\n",
    "    * That the prior predictive distributions simulates data that looks like it is compatible with our prior beliefs\n",
    "    * That the posterior predictive distribution looks like the observed data\n",
    "    * That fitting the model on the posterior predictive estimates the same parameters as the observations\n",
    "    * Diagnostic information from our inference algorithm:\n",
    "        * For example, MCMC algorithms can fail in various in ways, and there are measures that help detect some of the common failure modes\n",
    "\n",
    "#### Report\n",
    "* We need to report the results. This typically involves summarising the posterior distribution\n",
    "* Histograms, Box plots, tables, interactive visualisations can all be used to do so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Concrete algorithms for inference\n",
    "In general, we wouldn't use the grid type models we used for the `food` problem for real-world problems.\n",
    "\n",
    "* **Q: Why not?** [POLL]\n",
    "\n",
    "Practical algorithms for problems that involve *continuous* variables fall into three basic types. We'll see each type applied to the like/dislike problem.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Exact\n",
    "Very occasionally, we can compute the exact density function for a posterior distribution by some algebraic trickery. This is only possible if our prior and likelihood have a very specific form. Lots of classic Bayesian texts rely heavily on exact methods, but they are rarely useful in practice except in a few niches.\n",
    "\n",
    "#### Data structure\n",
    "* Parameter vectors (associated with density functions)\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "Direct computation.\n",
    "\n",
    "* We have a **parametric** form for our prior density $f_X(\\theta)$ (e.g. a normal distribution with parameters $\\mu$ and $\\sigma^2$).\n",
    "* We have a collection of observations\n",
    "* We have a **parametric** likelihood function that is compatible with our prior density function; $L(x|\\phi)$\n",
    "* We run a computation that computes closed-form a **parametric** density function for the posterior $g(\\psi)$.\n",
    "\n",
    "$f$, $L$ and $g$ don't have to have the same form (e.g. they might not all be normal), but they do have to be compatible (\"conjugate priors\"). \n",
    "\n",
    "\n",
    "#### Pros and cons\n",
    "\n",
    "* Advantages: Extremely efficient; no approximation error.\n",
    "* Disadvantages: constrains you to a small range of modelling choices; requires special implementation for each case; can be complicated to understand.\n",
    "\n",
    "#### Exact like/dislike\n",
    "If we *assume* that we can model the like/dislike distribution with a *beta* distribution (just a distribution over values from 0 to 1), then we can directly perform a Bayesian update.\n",
    "\n",
    "The distribution has two parameters $a, b$ and there is a simple algorithm that, given a count of likes and dislikes, returns a new $a, b$ for the updated distribution. This can only ever model distributions\n",
    "that have the beta \"shape\"; but this isn't that limiting in this simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 1,1\n",
    "# takes a,b and a like sequence\n",
    "# and returns an *exact* a and b for a Bayesian update\n",
    "\n",
    "def beta_update(a, b, likes):\n",
    "    k = sum([s=='ð'  for s in likes])\n",
    "    n = len(likes)\n",
    "    return a + k, b + n - k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_beta(a, b):\n",
    "    xs = np.linspace(0, 1, 512)    \n",
    "    beta_pdf = ss.beta(a, b).pdf(xs)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, beta_pdf)\n",
    "    ax.set_ylim(0,6)    \n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_xlabel(\"q\")\n",
    "    \n",
    "a, b = 1,1\n",
    "show_beta(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = beta_update(a, b, 'ðððððððð')\n",
    "show_beta(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = beta_update(a, b, 'ðððððððð')\n",
    "show_beta(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### MCMC\n",
    "MCMC (or Markov Chain Monte Carlo) is an approximation method that represents all distributions via collections of samples drawn from them. This makes it easy to apply arbitrary functions (just apply the function to each sample), but requires carefully designed algorithms to do Bayesian updates. \n",
    "\n",
    "In a Bayesian context, an MCMC sampler is used to draw samples from the posterior distribution.\n",
    "\n",
    "#### Data structure\n",
    "* Samples (i.e. sequences of values in the sample space *of parameters*)\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "Stochastic process, which gradually approximates the posterior. A true MCMC process makes small random steps in posterior space, and filters out or otherwise adjusts these random walks such that the samples tend to the posterior distribution.\n",
    "\n",
    "Common algorithms include Gibbs sampling (fast but limited); Metropolis-Hastings (general, but inefficient); Hamiltonian (fairly fast; requires derivatives).\n",
    "\n",
    "#### Pros and cons\n",
    "* Advantages: extremely general (\"one button inference\"); samples are easy to work with (just arrays of definite numbers); lots of sophisticated algorithms\n",
    "* Disadvantages: may not converge; lots of tuning and tweaking to get sampling to work; some problems are very resistant to sampling based solutions (e.g. exotic geometry, partially discrete problems)\n",
    "\n",
    "#### MCMC like/dislike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "samples = np.random.uniform(0, 1, n_samples) # uniform prior\n",
    "\n",
    "def importance_sample(samples, likes):    \n",
    "    # update samples based on likelihood\n",
    "    weights = np.array([np.exp(product_llik(samp, likes)) for samp in samples])\n",
    "    weights = weights / np.sum(weights)\n",
    "    # reproduce samples that are more highly weighted\n",
    "    resampled = np.random.choice(samples, size=samples.shape, p=weights)\n",
    "    resampled += np.random.normal(0, 0.02, resampled.shape)\n",
    "    return resampled\n",
    "\n",
    "def plot_samples(samples):\n",
    "    fig, ax = plt.subplots(figsize=(12,2))\n",
    "    xs = np.linspace(0, 1, 512)\n",
    "    ax.scatter(samples, samples*0+0.5, marker='|', c='C1', alpha=0.2, label=\"samples\")\n",
    "    ax.set_ylim(0,6)\n",
    "    kde = ss.gaussian_kde(samples)\n",
    "    ax.plot(xs, kde(xs), ls=':',label=\"Approx. density\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"q\")\n",
    "    ax.set_ylabel(\"Approx. density\")\n",
    "    \n",
    "    \n",
    "plot_samples(samples)\n",
    "updated = importance_sample(samples,  'ðððððððð')\n",
    "plot_samples(updated)\n",
    "updated = importance_sample(samples,  'ðððððððð')\n",
    "plot_samples(updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational\n",
    "Variational methods are somewhat like exact methods in that they involve manipulating the parameters of a density function algorithmically. But instead of being exact, we use density functions that are known to be computationally easy to apply, and we *optimise* the easy distribution to fit the (hard) posterior distribution.\n",
    "\n",
    "That is, we find some distribution $Q(X)$ and try and optimise it such that it fits the posterior distribution. We then have a parametric form for $Q$ that is easy to work with, but not one that exactly matches the true posterior shape. \n",
    "\n",
    "##### Data structure\n",
    "* Parameter vector (for a specially chosen class of functions)\n",
    "\n",
    "##### Algorithm\n",
    "\n",
    "Optimisation: there are various different strategies. Techniques like automatic differentiation variational inference (ADVI) are a fairly general way to apply variational inference to arbitrary problems, but are limited in the kinds of distribution that can be represented.\n",
    "\n",
    "#### Pros and cons\n",
    "* Advantages: Often very fast, especially compared to MCMC; covers the whole sample space instantly.\n",
    "* Disadvantages: Requires specific derivation for a given problem (though may be able to use automatic differentiation to help); may have consistent error that will never be resolved by additional computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## What is a Bayesian [IV]\n",
    "\n",
    "* Implements data generating processes as computational simulators of expected phenomena, and can simulate concrete implications of hypotheses.\n",
    "* Applies algorithms such as MCMC or variational inference to infer probability distributions over hidden states (latent variables) from observed data.\n",
    "* Reports and summarises inferences via approximations that are computationally tractable (e.g. via random samples)\n",
    "* Is typically concerned with *expectations* of a score function applied to a distribution, such as utility, or controversiality (as in the fruit example).\n",
    "* Freely fuses evidence from any source, in the past, present or future.\n",
    "\n",
    "\n",
    "### Why is this Computational HCI?\n",
    "\n",
    "* We build **statistical models** of user behaviour, and estimate parameters of that model from quantitative observations of data.\n",
    "* This is a **model-led approach** which has a strong mathematical underpinning and many powerful algorithms which can be brought to bear.\n",
    "* This is **robust** (it appropriately represents uncertainty) and **generative** (it can simulate behaviour compatible with observations).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Part III: Bayesian HCI](iii_bayesian_hci.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2eddf4f4d750c89334ec483a20beff3a977ef7807bc2815549a2bacb7799a306"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
